{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b5bc8d-a684-4e1c-ae2a-3e044210c9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "下面，我将为您提供一份融合了 双边滤波 和 卡尔曼滤波 的最终代码。这份代码将能有效解决您提出的两个问题，显著提升深度跟踪的平滑度和鲁棒性。引入filterpy库来实现卡尔曼滤波。您需要在您的环境中安装它：%pip install filterpy\n",
    "\n",
    "在视频处理函数中，为每个track_id创建一个独立的卡尔曼滤波器实例。\n",
    "\n",
    "在计算每个目标的深度后，使用卡尔曼滤波器进行预测和更新，得到平滑后的深度值。\n",
    "\n",
    "保留了“百分位截断均值”作为对单帧观测值的预处理，以提供更稳定的输入给卡尔曼滤波器。\n",
    "\n",
    "加入了对不再出现的目标的卡尔曼滤波器进行清理的逻辑，避免内存无限增长。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c593ae8-4142-40ce-821e-815ca79706ca",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [DEBUG] 步骤 0: 检查关键库版本...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/mot_depth/lib/python3.9/site-packages/torch/utils/cpp_extension.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import packaging  # type: ignore[attr-defined]\n",
      "/root/miniconda3/envs/mot_depth/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/envs/mot_depth/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [INFO] mmcv version: 1.7.2\n",
      ">>> [INFO] timm version: 0.6.12\n",
      ">>> [INFO] filterpy 库已成功导入。\n",
      ">>> [DEBUG] 步骤 0: 检查完成。\n",
      "============================================================\n",
      "\n",
      ">>> [DEBUG] 步骤 1: 开始导入核心库...\n",
      ">>> [DEBUG] 核心库 cv2, torch, numpy, ultralytics, tqdm, mmcv.Config 导入成功。\n",
      ">>> [DEBUG] 已将 '/root/autodl-tmp/Metric3D' 添加到系统路径。\n",
      ">>> [DEBUG] Metric3D 模块 'DepthModel' (作为 MonoDepthModel) 导入成功。\n",
      ">>> [DEBUG] 步骤 1: 所有库导入完成。\n",
      "============================================================\n",
      "\n",
      ">>> [DEBUG] 步骤 2: 配置模型和文件路径...\n",
      ">>> [DEBUG] 所有文件路径检查通过。\n",
      ">>> [DEBUG] 将要使用的设备: cuda\n",
      ">>> [DEBUG] 步骤 2: 配置完成。\n",
      "============================================================\n",
      "\n",
      ">>> [DEBUG] 步骤 3: 开始加载深度学习模型...\n",
      ">>> [DEBUG] 正在加载 YOLOv8 模型...\n",
      ">>> [DEBUG] YOLOv8 模型加载成功！\n",
      ">>> [INFO] 目标类别 'Car' 已找到, ID为: 0\n",
      ">>> [DEBUG] 正在加载 Metric3Dv2 模型...\n",
      ">>> [SUCCESS] Metric3Dv2 模型加载并移动到 GPU 成功！\n",
      ">>> [DEBUG] 步骤 3: 所有模型加载完成。\n",
      "============================================================\n",
      "\n",
      ">>> [DEBUG] 步骤 4: 定义视频处理函数...\n",
      ">>> [DEBUG] 步骤 4: 视频处理函数定义完成。\n",
      "============================================================\n",
      "\n",
      ">>> [DEBUG] 步骤 5: 开始执行主程序...\n",
      "\n",
      "--- 开始视频处理 ---\n",
      ">>> [INFO] 输入视频信息: 1242x374 @ 1.00 FPS, 共 154 帧。\n",
      ">>> [INFO] 处理后的视频将保存至: /root/autodl-tmp/output_video_kalman_filtered.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "视频处理进度: 100%|██████████| 154/154 [01:07<00:00,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 视频处理完成！ ---\n",
      ">>> [SUCCESS] 输出视频已成功保存到: /root/autodl-tmp/output_video_kalman_filtered.mp4\n",
      ">>> [DEBUG] 步骤 5: 主程序执行完毕。\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# 0. 关键依赖库检查 (用于调试)\n",
    "# ==============================================================================\n",
    "print(\">>> [DEBUG] 步骤 0: 检查关键库版本...\")\n",
    "try:\n",
    "    import mmcv\n",
    "    import timm\n",
    "    # --- 新增：导入 filterpy ---\n",
    "    from filterpy.kalman import KalmanFilter\n",
    "    print(f\">>> [INFO] mmcv version: {mmcv.__version__}\")\n",
    "    print(f\">>> [INFO] timm version: {timm.__version__}\")\n",
    "    print(\">>> [INFO] filterpy 库已成功导入。\")\n",
    "except ImportError as e:\n",
    "    print(f\"!!! [ERROR] 缺少核心库: {e}\")\n",
    "    print(\"!!! [HINT] 请确保已安装 filterpy (pip install filterpy)。\")\n",
    "    raise\n",
    "print(\">>> [DEBUG] 步骤 0: 检查完成。\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. 导入必要的库\n",
    "# ==============================================================================\n",
    "print(\">>> [DEBUG] 步骤 1: 开始导入核心库...\")\n",
    "try:\n",
    "    import cv2\n",
    "    import torch\n",
    "    import numpy as np\n",
    "    from ultralytics import YOLO\n",
    "    import sys\n",
    "    import os\n",
    "    from tqdm import tqdm\n",
    "    from mmcv import Config\n",
    "    print(\">>> [DEBUG] 核心库 cv2, torch, numpy, ultralytics, tqdm, mmcv.Config 导入成功。\")\n",
    "except ImportError as e:\n",
    "    print(f\"!!! [ERROR] 导入核心库失败: {e}\")\n",
    "    print(\"!!! [HINT] 请确保您已经按照教程正确安装了所有依赖。\")\n",
    "    raise\n",
    "\n",
    "# --- 导入 Metric3D 相关的模块 ---\n",
    "METRIC3D_PATH = '/root/autodl-tmp/Metric3D'\n",
    "if METRIC3D_PATH not in sys.path:\n",
    "    sys.path.insert(0, METRIC3D_PATH)\n",
    "    print(f\">>> [DEBUG] 已将 '{METRIC3D_PATH}' 添加到系统路径。\")\n",
    "\n",
    "try:\n",
    "    from mono.model.monodepth_model import DepthModel as MonoDepthModel\n",
    "    print(\">>> [DEBUG] Metric3D 模块 'DepthModel' (作为 MonoDepthModel) 导入成功。\")\n",
    "except ImportError as e:\n",
    "    print(f\"!!! [ERROR] 从 Metric3D 导入模块失败: {e}\")\n",
    "    print(f\"!!! [HINT] 请确认 Metric3D 的代码库是否存在于 '{METRIC3D_PATH}' 路径下。\")\n",
    "    raise\n",
    "\n",
    "print(\">>> [DEBUG] 步骤 1: 所有库导入完成。\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. 配置区域与路径检查\n",
    "# ==============================================================================\n",
    "print(\">>> [DEBUG] 步骤 2: 配置模型和文件路径...\")\n",
    "\n",
    "YOLO_MODEL_PATH = '/root/autodl-tmp/epoch30.pt'\n",
    "METRIC3D_MODEL_PATH = '/root/autodl-tmp/weights/metric_depth_vit_large_800k.pth'\n",
    "METRIC3D_CONFIG_PATH = '/root/autodl-tmp/Metric3D/mono/configs/HourglassDecoder/vit.raft5.large.py'\n",
    "INPUT_VIDEO_PATH = '/root/autodl-tmp/0000.mp4'\n",
    "OUTPUT_VIDEO_PATH = '/root/autodl-tmp/output_video_kalman_filtered.mp4' # <-- 修改输出文件名\n",
    "TRACKER_CONFIG_PATH = '/root/autodl-tmp/bytetrack.yaml'\n",
    "\n",
    "\n",
    "paths_to_check = {\n",
    "    \"YOLOv8 权重\": YOLO_MODEL_PATH,\n",
    "    \"Metric3D 权重\": METRIC3D_MODEL_PATH,\n",
    "    \"Metric3D 配置\": METRIC3D_CONFIG_PATH,\n",
    "    \"输入视频\": INPUT_VIDEO_PATH,\n",
    "    \"跟踪器配置\": TRACKER_CONFIG_PATH,\n",
    "}\n",
    "all_paths_ok = True\n",
    "for name, path in paths_to_check.items():\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"!!! [ERROR] 路径检查失败: {name} 文件未找到于 '{path}'\")\n",
    "        all_paths_ok = False\n",
    "if not all_paths_ok:\n",
    "    raise FileNotFoundError(\"一个或多个关键文件路径无效。请确保已创建 bytetrack.yaml 文件。\")\n",
    "else:\n",
    "    print(\">>> [DEBUG] 所有文件路径检查通过。\")\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\">>> [DEBUG] 将要使用的设备: {DEVICE}\")\n",
    "if DEVICE.type == 'cpu':\n",
    "    print(\"!!! [WARNING] 未检测到 CUDA 设备，将使用 CPU 运行。速度会很慢！\")\n",
    "\n",
    "print(\">>> [DEBUG] 步骤 2: 配置完成。\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. 模型加载\n",
    "# ==============================================================================\n",
    "print(\">>> [DEBUG] 步骤 3: 开始加载深度学习模型...\")\n",
    "# --- 加载 YOLOv8 & ByteTrack 模型 ---\n",
    "try:\n",
    "    print(\">>> [DEBUG] 正在加载 YOLOv8 模型...\")\n",
    "    yolo_model = YOLO(YOLO_MODEL_PATH)\n",
    "    print(\">>> [DEBUG] YOLOv8 模型加载成功！\")\n",
    "\n",
    "    TARGET_CLASS_NAME = 'Car'\n",
    "    TARGET_CLASS_ID = [k for k, v in yolo_model.names.items() if v == TARGET_CLASS_NAME][0]\n",
    "    print(f\">>> [INFO] 目标类别 '{TARGET_CLASS_NAME}' 已找到, ID为: {TARGET_CLASS_ID}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"!!! [ERROR] 加载 YOLOv8 模型或查找类别ID时失败: {e}\")\n",
    "    raise\n",
    "\n",
    "# --- 加载 Metric3Dv2 模型 ---\n",
    "try:\n",
    "    print(\">>> [DEBUG] 正在加载 Metric3Dv2 模型...\")\n",
    "    \n",
    "    cfg = Config.fromfile(METRIC3D_CONFIG_PATH)\n",
    "    cfg.model.backbone.use_mask_token = False\n",
    "    metric3d_model = MonoDepthModel(cfg).to(DEVICE)\n",
    "    \n",
    "    checkpoint = torch.load(METRIC3D_MODEL_PATH, map_location=DEVICE)\n",
    "    state_dict = checkpoint.get('model_state_dict', checkpoint.get('model', checkpoint))\n",
    "    metric3d_model.load_state_dict(state_dict, strict=False)\n",
    "    \n",
    "    metric3d_model.eval()\n",
    "    print(\">>> [SUCCESS] Metric3Dv2 模型加载并移动到 GPU 成功！\")\n",
    "except Exception as e:\n",
    "    print(f\"!!! [FATAL ERROR] 加载 Metric3Dv2 模型时出错: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    raise\n",
    "\n",
    "print(\">>> [DEBUG] 步骤 3: 所有模型加载完成。\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 4. 视频处理主函数\n",
    "# ==============================================================================\n",
    "print(\">>> [DEBUG] 步骤 4: 定义视频处理函数...\")\n",
    "def process_video_debug(input_path, output_path):\n",
    "    print(\"\\n--- 开始视频处理 ---\")\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"!!! [ERROR] 无法打开视频文件: {input_path}\")\n",
    "        return\n",
    "\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    metric3d_input_size = (cfg.data_basic['vit_size'][1], cfg.data_basic['vit_size'][0])\n",
    "    \n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "    \n",
    "    print(f\">>> [INFO] 输入视频信息: {width}x{height} @ {fps:.2f} FPS, 共 {total_frames} 帧。\")\n",
    "    print(f\">>> [INFO] 处理后的视频将保存至: {output_path}\")\n",
    "\n",
    "    # ============================================================\n",
    "    # === 新增: 初始化卡尔曼滤波器字典 ===\n",
    "    # ============================================================\n",
    "    kalman_filters = {}\n",
    "    # ============================================================\n",
    "\n",
    "    with tqdm(total=total_frames, desc=\"视频处理进度\") as pbar:\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            track_results = yolo_model.track(\n",
    "                frame, \n",
    "                persist=True, \n",
    "                verbose=False, \n",
    "                tracker=TRACKER_CONFIG_PATH,\n",
    "                classes=[TARGET_CLASS_ID] \n",
    "            )\n",
    "            \n",
    "            annotated_frame = frame.copy()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                rgb_frame_resized = cv2.resize(rgb_frame, metric3d_input_size)\n",
    "                rgb_torch = torch.from_numpy(rgb_frame_resized).permute(2, 0, 1).unsqueeze(0).float().to(DEVICE) / 255.0\n",
    "                pred_output = metric3d_model(data={'input': rgb_torch})\n",
    "                pred_depth_np = pred_output[0].squeeze().cpu().numpy()\n",
    "                pred_depth_resized = cv2.resize(pred_depth_np, (width, height)).astype(np.float32)\n",
    "\n",
    "                pred_depth_filtered = cv2.bilateralFilter(pred_depth_resized, d=5, sigmaColor=0.2, sigmaSpace=15)\n",
    "\n",
    "            boxes = track_results[0].boxes.xyxy.cpu().numpy()\n",
    "            track_ids = track_results[0].boxes.id.int().cpu().tolist() if track_results[0].boxes.id is not None else []\n",
    "            \n",
    "            # --- 用于记录本帧仍然活跃的track_id ---\n",
    "            active_track_ids = set()\n",
    "\n",
    "            if len(track_ids) > 0:\n",
    "                for box, track_id in zip(boxes, track_ids):\n",
    "                    active_track_ids.add(track_id)\n",
    "                    x1, y1, x2, y2 = map(int, box)\n",
    "                    \n",
    "                    cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                    \n",
    "                    box_w, box_h = x2 - x1, y2 - y1\n",
    "                    roi_w, roi_h = int(box_w * 0.5), int(box_h * 0.5)\n",
    "                    roi_x1 = max(x1 + (box_w - roi_w) // 2, 0)\n",
    "                    roi_y1 = max(y1 + (box_h - roi_h) // 2, 0)\n",
    "                    roi_x2 = min(roi_x1 + roi_w, width)\n",
    "                    roi_y2 = min(roi_y1 + roi_h, height)\n",
    "\n",
    "                    depth_roi = pred_depth_filtered[roi_y1:roi_y2, roi_x1:roi_x2]\n",
    "                    \n",
    "                    if depth_roi.size > 0:\n",
    "                        # 步骤1: 对当前帧的观测值进行预处理，去除极端值\n",
    "                        sorted_depths = np.sort(depth_roi.flatten())\n",
    "                        cut_off = int(len(sorted_depths) * 0.10) # 稍微增加截断比例\n",
    "                        \n",
    "                        if len(sorted_depths) > 2 * cut_off:\n",
    "                            filtered_depths = sorted_depths[cut_off:-cut_off]\n",
    "                            observed_depth = np.mean(filtered_depths) if filtered_depths.size > 0 else 0\n",
    "                        else:\n",
    "                            observed_depth = np.mean(sorted_depths) if sorted_depths.size > 0 else 0\n",
    "                        \n",
    "                        # 如果观测到的深度异常（例如为0），则跳过卡尔曼滤波的更新步骤\n",
    "                        if observed_depth <= 0:\n",
    "                            continue\n",
    "\n",
    "                        # ============================================================\n",
    "                        # === 新增: 应用卡尔曼滤波进行时间一致性平滑 ===\n",
    "                        # ============================================================\n",
    "                        if track_id not in kalman_filters:\n",
    "                            # 1. 为新目标初始化卡尔曼滤波器\n",
    "                            kf = KalmanFilter(dim_x=2, dim_z=1) # 状态量x=[深度, 深度变化速度], 观测z=[深度]\n",
    "                            kf.x = np.array([observed_depth, 0.])   # 初始状态 [depth, velocity]\n",
    "                            kf.F = np.array([[1., 1.], [0., 1.]])    # 状态转移矩阵 (匀速模型)\n",
    "                            kf.H = np.array([[1., 0.]])             # 观测矩阵\n",
    "                            kf.P *= 100.                            # 初始状态协方差\n",
    "                            kf.R = 10                               # 测量噪声协方差 (关键可调参数)\n",
    "                            kf.Q = 0.1                              # 过程噪声协方差 (关键可调参数)\n",
    "                            kalman_filters[track_id] = kf\n",
    "                        else:\n",
    "                            kf = kalman_filters[track_id]\n",
    "\n",
    "                        # 2. 预测与更新\n",
    "                        kf.predict()\n",
    "                        kf.update(observed_depth)\n",
    "                        \n",
    "                        # 3. 获取平滑后的深度值\n",
    "                        smoothed_depth = kf.x[0]\n",
    "                        # ============================================================\n",
    "                        \n",
    "                        depth_text = f\"ID:{track_id} D:{smoothed_depth:.2f}m\"\n",
    "                        (text_w, text_h), _ = cv2.getTextSize(depth_text, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)\n",
    "                        cv2.rectangle(annotated_frame, (x1, y1 - 25), (x1 + text_w + 5, y1 - 5), (0, 100, 0), -1)\n",
    "                        cv2.putText(annotated_frame, depth_text, (x1 + 2, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "            \n",
    "            # --- 清理不再活跃的目标的滤波器，防止内存泄漏 ---\n",
    "            inactive_ids = set(kalman_filters.keys()) - active_track_ids\n",
    "            for inactive_id in inactive_ids:\n",
    "                del kalman_filters[inactive_id]\n",
    "\n",
    "            out.write(annotated_frame)\n",
    "            pbar.update(1)\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(f\"\\n--- 视频处理完成！ ---\")\n",
    "    print(f\">>> [SUCCESS] 输出视频已成功保存到: {output_path}\")\n",
    "\n",
    "print(\">>> [DEBUG] 步骤 4: 视频处理函数定义完成。\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 5. 运行主程序\n",
    "# ==============================================================================\n",
    "print(\">>> [DEBUG] 步骤 5: 开始执行主程序...\")\n",
    "try:\n",
    "    process_video_debug(INPUT_VIDEO_PATH, OUTPUT_VIDEO_PATH)\n",
    "except Exception as e:\n",
    "    print(f\"!!! [FATAL ERROR] 在视频处理过程中发生严重错误: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    print(\"!!! [HINT] 请检查上面的错误信息。可能的原因包括：CUDA内存不足、模型与输入数据维度不匹配等。\")\n",
    "\n",
    "print(\">>> [DEBUG] 步骤 5: 主程序执行完毕。\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c9ac67-7053-4afc-9ecd-4db9af07423b",
   "metadata": {},
   "outputs": [],
   "source": [
    "结合K-Means聚类的完整代码\n",
    "下面的代码在上一版（双边滤波+卡尔曼滤波）的基础上，用K-Means聚类替换了原来的“百分位截断均值”方法。\n",
    "\n",
    "关键改动:\n",
    "\n",
    "引入sklearn.cluster.KMeans。您需要在环境中安装scikit-learn：%pip install scikit-learn。\n",
    "\n",
    "在深度计算部分，我们使用K-Means将ROI中的深度值聚为两类。\n",
    "\n",
    "我们选取两个聚类中心中深度值较小（即较近）的那个作为当前帧的“观测深度”。\n",
    "\n",
    "为了代码的健壮性，如果ROI中的像素点太少（少于k个），K-Means会失败，此时我们回退到使用均值的方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a9ba54a-a3ad-4ba1-90c8-b083f3b5d6ab",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [DEBUG] 步骤 0: 检查关键库版本...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/mot_depth/lib/python3.9/site-packages/torch/utils/cpp_extension.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import packaging  # type: ignore[attr-defined]\n",
      "/root/miniconda3/envs/mot_depth/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/envs/mot_depth/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [INFO] mmcv version: 1.7.2\n",
      ">>> [INFO] timm version: 0.6.12\n",
      ">>> [INFO] filterpy 和 scikit-learn 库已成功导入。\n",
      ">>> [DEBUG] 步骤 0: 检查完成。\n",
      "============================================================\n",
      "\n",
      ">>> [DEBUG] 步骤 1: 开始导入核心库...\n",
      ">>> [DEBUG] 核心库 cv2, torch, numpy, ultralytics, tqdm, mmcv.Config 导入成功。\n",
      ">>> [DEBUG] 已将 '/root/autodl-tmp/Metric3D' 添加到系统路径。\n",
      ">>> [DEBUG] Metric3D 模块 'DepthModel' (作为 MonoDepthModel) 导入成功。\n",
      ">>> [DEBUG] 步骤 1: 所有库导入完成。\n",
      "============================================================\n",
      "\n",
      ">>> [DEBUG] 步骤 2: 配置模型和文件路径...\n",
      ">>> [DEBUG] 所有文件路径检查通过。\n",
      ">>> [DEBUG] 将要使用的设备: cuda\n",
      ">>> [DEBUG] 步骤 2: 配置完成。\n",
      "============================================================\n",
      "\n",
      ">>> [DEBUG] 步骤 3: 开始加载深度学习模型...\n",
      ">>> [DEBUG] 正在加载 YOLOv8 模型...\n",
      ">>> [INFO] 目标类别 'Car' 已找到, ID为: 0\n",
      ">>> [DEBUG] 正在加载 Metric3Dv2 模型...\n",
      ">>> [SUCCESS] Metric3Dv2 模型加载并移动到 GPU 成功！\n",
      ">>> [DEBUG] 步骤 3: 所有模型加载完成。\n",
      "============================================================\n",
      "\n",
      ">>> [DEBUG] 步骤 4: 定义视频处理函数...\n",
      ">>> [DEBUG] 步骤 4: 视频处理函数定义完成。\n",
      "============================================================\n",
      "\n",
      ">>> [DEBUG] 步骤 5: 开始执行主程序...\n",
      "\n",
      "--- 开始视频处理 ---\n",
      ">>> [INFO] 输入视频信息: 1242x374 @ 1.00 FPS, 共 154 帧。\n",
      ">>> [INFO] 处理后的视频将保存至: /root/autodl-tmp/output_video_kmeans_filtered.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "视频处理进度: 100%|██████████| 154/154 [01:09<00:00,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 视频处理完成！ ---\n",
      ">>> [SUCCESS] 输出视频已成功保存到: /root/autodl-tmp/output_video_kmeans_filtered.mp4\n",
      ">>> [DEBUG] 步骤 5: 主程序执行完毕。\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# 0. 关键依赖库检查 (用于调试)\n",
    "# ==============================================================================\n",
    "print(\">>> [DEBUG] 步骤 0: 检查关键库版本...\")\n",
    "try:\n",
    "    import mmcv\n",
    "    import timm\n",
    "    from filterpy.kalman import KalmanFilter\n",
    "    # --- 新增：导入 KMeans ---\n",
    "    from sklearn.cluster import KMeans\n",
    "    print(f\">>> [INFO] mmcv version: {mmcv.__version__}\")\n",
    "    print(f\">>> [INFO] timm version: {timm.__version__}\")\n",
    "    print(\">>> [INFO] filterpy 和 scikit-learn 库已成功导入。\")\n",
    "except ImportError as e:\n",
    "    print(f\"!!! [ERROR] 缺少核心库: {e}\")\n",
    "    print(\"!!! [HINT] 请确保已安装 filterpy (pip install filterpy) 和 scikit-learn (pip install scikit-learn)。\")\n",
    "    raise\n",
    "print(\">>> [DEBUG] 步骤 0: 检查完成。\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. 导入必要的库\n",
    "# ==============================================================================\n",
    "print(\">>> [DEBUG] 步骤 1: 开始导入核心库...\")\n",
    "try:\n",
    "    import cv2\n",
    "    import torch\n",
    "    import numpy as np\n",
    "    from ultralytics import YOLO\n",
    "    import sys\n",
    "    import os\n",
    "    from tqdm import tqdm\n",
    "    from mmcv import Config\n",
    "    print(\">>> [DEBUG] 核心库 cv2, torch, numpy, ultralytics, tqdm, mmcv.Config 导入成功。\")\n",
    "except ImportError as e:\n",
    "    print(f\"!!! [ERROR] 导入核心库失败: {e}\")\n",
    "    print(\"!!! [HINT] 请确保您已经按照教程正确安装了所有依赖。\")\n",
    "    raise\n",
    "\n",
    "# --- 导入 Metric3D 相关的模块 ---\n",
    "METRIC3D_PATH = '/root/autodl-tmp/Metric3D'\n",
    "if METRIC3D_PATH not in sys.path:\n",
    "    sys.path.insert(0, METRIC3D_PATH)\n",
    "    print(f\">>> [DEBUG] 已将 '{METRIC3D_PATH}' 添加到系统路径。\")\n",
    "\n",
    "try:\n",
    "    from mono.model.monodepth_model import DepthModel as MonoDepthModel\n",
    "    print(\">>> [DEBUG] Metric3D 模块 'DepthModel' (作为 MonoDepthModel) 导入成功。\")\n",
    "except ImportError as e:\n",
    "    print(f\"!!! [ERROR] 从 Metric3D 导入模块失败: {e}\")\n",
    "    print(f\"!!! [HINT] 请确认 Metric3D 的代码库是否存在于 '{METRIC3D_PATH}' 路径下。\")\n",
    "    raise\n",
    "\n",
    "print(\">>> [DEBUG] 步骤 1: 所有库导入完成。\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. 配置区域与路径检查\n",
    "# ==============================================================================\n",
    "print(\">>> [DEBUG] 步骤 2: 配置模型和文件路径...\")\n",
    "\n",
    "YOLO_MODEL_PATH = '/root/autodl-tmp/epoch30.pt'\n",
    "METRIC3D_MODEL_PATH = '/root/autodl-tmp/weights/metric_depth_vit_large_800k.pth'\n",
    "METRIC3D_CONFIG_PATH = '/root/autodl-tmp/Metric3D/mono/configs/HourglassDecoder/vit.raft5.large.py'\n",
    "INPUT_VIDEO_PATH = '/root/autodl-tmp/0000.mp4'\n",
    "OUTPUT_VIDEO_PATH = '/root/autodl-tmp/output_video_kmeans_filtered.mp4' # <-- 修改输出文件名\n",
    "TRACKER_CONFIG_PATH = '/root/autodl-tmp/bytetrack.yaml'\n",
    "\n",
    "\n",
    "paths_to_check = {\n",
    "    \"YOLOv8 权重\": YOLO_MODEL_PATH,\n",
    "    \"Metric3D 权重\": METRIC3D_MODEL_PATH,\n",
    "    \"Metric3D 配置\": METRIC3D_CONFIG_PATH,\n",
    "    \"输入视频\": INPUT_VIDEO_PATH,\n",
    "    \"跟踪器配置\": TRACKER_CONFIG_PATH,\n",
    "}\n",
    "all_paths_ok = True\n",
    "for name, path in paths_to_check.items():\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"!!! [ERROR] 路径检查失败: {name} 文件未找到于 '{path}'\")\n",
    "        all_paths_ok = False\n",
    "if not all_paths_ok:\n",
    "    raise FileNotFoundError(\"一个或多个关键文件路径无效。请确保已创建 bytetrack.yaml 文件。\")\n",
    "else:\n",
    "    print(\">>> [DEBUG] 所有文件路径检查通过。\")\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\">>> [DEBUG] 将要使用的设备: {DEVICE}\")\n",
    "if DEVICE.type == 'cpu':\n",
    "    print(\"!!! [WARNING] 未检测到 CUDA 设备，将使用 CPU 运行。速度会很慢！\")\n",
    "\n",
    "print(\">>> [DEBUG] 步骤 2: 配置完成。\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. 模型加载\n",
    "# ==============================================================================\n",
    "print(\">>> [DEBUG] 步骤 3: 开始加载深度学习模型...\")\n",
    "try:\n",
    "    print(\">>> [DEBUG] 正在加载 YOLOv8 模型...\")\n",
    "    yolo_model = YOLO(YOLO_MODEL_PATH)\n",
    "\n",
    "    TARGET_CLASS_NAME = 'Car'\n",
    "    TARGET_CLASS_ID = [k for k, v in yolo_model.names.items() if v == TARGET_CLASS_NAME][0]\n",
    "    print(f\">>> [INFO] 目标类别 '{TARGET_CLASS_NAME}' 已找到, ID为: {TARGET_CLASS_ID}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"!!! [ERROR] 加载 YOLOv8 模型或查找类别ID时失败: {e}\")\n",
    "    raise\n",
    "\n",
    "try:\n",
    "    print(\">>> [DEBUG] 正在加载 Metric3Dv2 模型...\")\n",
    "    \n",
    "    cfg = Config.fromfile(METRIC3D_CONFIG_PATH)\n",
    "    cfg.model.backbone.use_mask_token = False\n",
    "    metric3d_model = MonoDepthModel(cfg).to(DEVICE)\n",
    "    \n",
    "    checkpoint = torch.load(METRIC3D_MODEL_PATH, map_location=DEVICE)\n",
    "    state_dict = checkpoint.get('model_state_dict', checkpoint.get('model', checkpoint))\n",
    "    metric3d_model.load_state_dict(state_dict, strict=False)\n",
    "    \n",
    "    metric3d_model.eval()\n",
    "    print(\">>> [SUCCESS] Metric3Dv2 模型加载并移动到 GPU 成功！\")\n",
    "except Exception as e:\n",
    "    print(f\"!!! [FATAL ERROR] 加载 Metric3Dv2 模型时出错: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    raise\n",
    "\n",
    "print(\">>> [DEBUG] 步骤 3: 所有模型加载完成。\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 4. 视频处理主函数\n",
    "# ==============================================================================\n",
    "print(\">>> [DEBUG] 步骤 4: 定义视频处理函数...\")\n",
    "def process_video_debug(input_path, output_path):\n",
    "    print(\"\\n--- 开始视频处理 ---\")\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"!!! [ERROR] 无法打开视频文件: {input_path}\")\n",
    "        return\n",
    "\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    metric3d_input_size = (cfg.data_basic['vit_size'][1], cfg.data_basic['vit_size'][0])\n",
    "    \n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "    \n",
    "    print(f\">>> [INFO] 输入视频信息: {width}x{height} @ {fps:.2f} FPS, 共 {total_frames} 帧。\")\n",
    "    print(f\">>> [INFO] 处理后的视频将保存至: {output_path}\")\n",
    "\n",
    "    kalman_filters = {}\n",
    "\n",
    "    with tqdm(total=total_frames, desc=\"视频处理进度\") as pbar:\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            track_results = yolo_model.track(\n",
    "                frame, \n",
    "                persist=True, \n",
    "                verbose=False, \n",
    "                tracker=TRACKER_CONFIG_PATH,\n",
    "                classes=[TARGET_CLASS_ID] \n",
    "            )\n",
    "            \n",
    "            annotated_frame = frame.copy()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                rgb_frame_resized = cv2.resize(rgb_frame, metric3d_input_size)\n",
    "                rgb_torch = torch.from_numpy(rgb_frame_resized).permute(2, 0, 1).unsqueeze(0).float().to(DEVICE) / 255.0\n",
    "                pred_output = metric3d_model(data={'input': rgb_torch})\n",
    "                pred_depth_np = pred_output[0].squeeze().cpu().numpy()\n",
    "                pred_depth_resized = cv2.resize(pred_depth_np, (width, height)).astype(np.float32)\n",
    "                pred_depth_filtered = cv2.bilateralFilter(pred_depth_resized, d=5, sigmaColor=0.2, sigmaSpace=15)\n",
    "\n",
    "            boxes = track_results[0].boxes.xyxy.cpu().numpy()\n",
    "            track_ids = track_results[0].boxes.id.int().cpu().tolist() if track_results[0].boxes.id is not None else []\n",
    "            \n",
    "            active_track_ids = set()\n",
    "\n",
    "            if len(track_ids) > 0:\n",
    "                for box, track_id in zip(boxes, track_ids):\n",
    "                    active_track_ids.add(track_id)\n",
    "                    x1, y1, x2, y2 = map(int, box)\n",
    "                    \n",
    "                    cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                    \n",
    "                    box_w, box_h = x2 - x1, y2 - y1\n",
    "                    roi_w, roi_h = int(box_w * 0.5), int(box_h * 0.5)\n",
    "                    roi_x1 = max(x1 + (box_w - roi_w) // 2, 0)\n",
    "                    roi_y1 = max(y1 + (box_h - roi_h) // 2, 0)\n",
    "                    roi_x2 = min(roi_x1 + roi_w, width)\n",
    "                    roi_y2 = min(roi_y1 + roi_h, height)\n",
    "\n",
    "                    depth_roi = pred_depth_filtered[roi_y1:roi_y2, roi_x1:roi_x2]\n",
    "                    \n",
    "                    if depth_roi.size > 2: # K-Means至少需要K个点\n",
    "                        # ============================================================\n",
    "                        # === 新增: 使用 K-Means 聚类来确定前景深度 ===\n",
    "                        # ============================================================\n",
    "                        try:\n",
    "                            # 1. 准备数据: 将ROI内的深度值展平为一维数组\n",
    "                            pixels = depth_roi.flatten().reshape(-1, 1)\n",
    "\n",
    "                            # 2. 执行K-Means聚类, k=2 表示期望分为前景和背景两个簇\n",
    "                            # n_init='auto' 会自动选择最佳的初始化次数\n",
    "                            kmeans = KMeans(n_clusters=2, n_init='auto', random_state=0).fit(pixels)\n",
    "                            \n",
    "                            # 3. 找到前景簇: 前景通常是距离更近的, 所以其簇中心的深度值更小\n",
    "                            foreground_cluster_center = min(kmeans.cluster_centers_.flatten())\n",
    "                            \n",
    "                            observed_depth = foreground_cluster_center\n",
    "\n",
    "                        except Exception as e:\n",
    "                            # 如果K-Means失败(例如ROI内所有像素值都一样), 则回退到使用均值\n",
    "                            observed_depth = np.mean(depth_roi)\n",
    "                        # ============================================================\n",
    "                    elif depth_roi.size > 0:\n",
    "                        # 如果点太少, 直接用均值\n",
    "                        observed_depth = np.mean(depth_roi)\n",
    "                    else:\n",
    "                        continue\n",
    "                        \n",
    "                    if observed_depth <= 0:\n",
    "                        continue\n",
    "\n",
    "                    if track_id not in kalman_filters:\n",
    "                        kf = KalmanFilter(dim_x=2, dim_z=1)\n",
    "                        kf.x = np.array([observed_depth, 0.])\n",
    "                        kf.F = np.array([[1., 1.], [0., 1.]])\n",
    "                        kf.H = np.array([[1., 0.]])\n",
    "                        kf.P *= 100.\n",
    "                        kf.R = 10\n",
    "                        kf.Q = 0.1\n",
    "                        kalman_filters[track_id] = kf\n",
    "                    else:\n",
    "                        kf = kalman_filters[track_id]\n",
    "\n",
    "                    kf.predict()\n",
    "                    kf.update(observed_depth)\n",
    "                    smoothed_depth = kf.x[0]\n",
    "                    \n",
    "                    depth_text = f\"ID:{track_id} D:{smoothed_depth:.2f}m\"\n",
    "                    (text_w, text_h), _ = cv2.getTextSize(depth_text, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)\n",
    "                    cv2.rectangle(annotated_frame, (x1, y1 - 25), (x1 + text_w + 5, y1 - 5), (0, 100, 0), -1)\n",
    "                    cv2.putText(annotated_frame, depth_text, (x1 + 2, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "            \n",
    "            inactive_ids = set(kalman_filters.keys()) - active_track_ids\n",
    "            for inactive_id in inactive_ids:\n",
    "                del kalman_filters[inactive_id]\n",
    "\n",
    "            out.write(annotated_frame)\n",
    "            pbar.update(1)\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(f\"\\n--- 视频处理完成！ ---\")\n",
    "    print(f\">>> [SUCCESS] 输出视频已成功保存到: {output_path}\")\n",
    "\n",
    "print(\">>> [DEBUG] 步骤 4: 视频处理函数定义完成。\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 5. 运行主程序\n",
    "# ==============================================================================\n",
    "print(\">>> [DEBUG] 步骤 5: 开始执行主程序...\")\n",
    "try:\n",
    "    process_video_debug(INPUT_VIDEO_PATH, OUTPUT_VIDEO_PATH)\n",
    "except Exception as e:\n",
    "    print(f\"!!! [FATAL ERROR] 在视频处理过程中发生严重错误: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    print(\"!!! [HINT] 请检查上面的错误信息。可能的原因包括：CUDA内存不足、模型与输入数据维度不匹配等。\")\n",
    "\n",
    "print(\">>> [DEBUG] 步骤 5: 主程序执行完毕。\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1365972f-8930-4503-b37d-084243eb78fd",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [DEBUG] 步骤 0: 检查关键库版本...\n",
      ">>> [INFO] mmcv version: 1.7.2\n",
      ">>> [INFO] timm version: 0.6.12\n",
      ">>> [INFO] filterpy 和 scikit-learn (GMM) 库已成功导入。\n",
      ">>> [DEBUG] 步骤 0: 检查完成。\n",
      "============================================================\n",
      "\n",
      ">>> [DEBUG] 步骤 1: 开始导入核心库...\n",
      ">>> [DEBUG] 核心库 cv2, torch, numpy, ultralytics, tqdm, mmcv.Config 导入成功。\n",
      ">>> [DEBUG] Metric3D 模块 'DepthModel' (作为 MonoDepthModel) 导入成功。\n",
      ">>> [DEBUG] 步骤 1: 所有库导入完成。\n",
      "============================================================\n",
      "\n",
      ">>> [DEBUG] 步骤 2: 配置模型和文件路径...\n",
      ">>> [DEBUG] 所有文件路径检查通过。\n",
      ">>> [DEBUG] 将要使用的设备: cuda\n",
      ">>> [DEBUG] 步骤 2: 配置完成。\n",
      "============================================================\n",
      "\n",
      ">>> [DEBUG] 步骤 3: 开始加载深度学习模型...\n",
      ">>> [INFO] 目标类别 'Car' 已找到, ID为: 0\n",
      ">>> [SUCCESS] Metric3Dv2 模型加载并移动到 GPU 成功！\n",
      ">>> [DEBUG] 步骤 3: 所有模型加载完成。\n",
      "============================================================\n",
      "\n",
      ">>> [DEBUG] 步骤 4: 定义视频处理函数...\n",
      ">>> [DEBUG] 步骤 5: 开始执行主程序...\n",
      "\n",
      "--- 开始视频处理 ---\n",
      ">>> [INFO] 输入视频信息: 1242x374 @ 1.00 FPS, 共 154 帧。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "视频处理进度: 100%|██████████| 154/154 [01:25<00:00,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 视频处理完成！ ---\n",
      ">>> [SUCCESS] 输出视频已成功保存到: /root/autodl-tmp/output_video_gmm_filtered.mp4\n",
      ">>> [DEBUG] 步骤 5: 主程序执行完毕。\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# 0. 关键依赖库检查 (用于调试)\n",
    "# ==============================================================================\n",
    "print(\">>> [DEBUG] 步骤 0: 检查关键库版本...\")\n",
    "try:\n",
    "    import mmcv\n",
    "    import timm\n",
    "    from filterpy.kalman import KalmanFilter\n",
    "    # --- 导入 GMM ---\n",
    "    from sklearn.mixture import GaussianMixture\n",
    "    print(f\">>> [INFO] mmcv version: {mmcv.__version__}\")\n",
    "    print(f\">>> [INFO] timm version: {timm.__version__}\")\n",
    "    print(\">>> [INFO] filterpy 和 scikit-learn (GMM) 库已成功导入。\")\n",
    "except ImportError as e:\n",
    "    print(f\"!!! [ERROR] 缺少核心库: {e}\")\n",
    "    print(\"!!! [HINT] 请确保已安装 filterpy (pip install filterpy) 和 scikit-learn (pip install scikit-learn)。\")\n",
    "    raise\n",
    "print(\">>> [DEBUG] 步骤 0: 检查完成。\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. 导入必要的库\n",
    "# ==============================================================================\n",
    "print(\">>> [DEBUG] 步骤 1: 开始导入核心库...\")\n",
    "try:\n",
    "    import cv2\n",
    "    import torch\n",
    "    import numpy as np\n",
    "    from ultralytics import YOLO\n",
    "    import sys\n",
    "    import os\n",
    "    from tqdm import tqdm\n",
    "    from mmcv import Config\n",
    "    print(\">>> [DEBUG] 核心库 cv2, torch, numpy, ultralytics, tqdm, mmcv.Config 导入成功。\")\n",
    "except ImportError as e:\n",
    "    print(f\"!!! [ERROR] 导入核心库失败: {e}\")\n",
    "    raise\n",
    "\n",
    "# --- 导入 Metric3D 相关的模块 ---\n",
    "METRIC3D_PATH = '/root/autodl-tmp/Metric3D'\n",
    "if METRIC3D_PATH not in sys.path:\n",
    "    sys.path.insert(0, METRIC3D_PATH)\n",
    "\n",
    "try:\n",
    "    from mono.model.monodepth_model import DepthModel as MonoDepthModel\n",
    "    print(\">>> [DEBUG] Metric3D 模块 'DepthModel' (作为 MonoDepthModel) 导入成功。\")\n",
    "except ImportError as e:\n",
    "    print(f\"!!! [ERROR] 从 Metric3D 导入模块失败: {e}\")\n",
    "    raise\n",
    "\n",
    "print(\">>> [DEBUG] 步骤 1: 所有库导入完成。\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. 配置区域与路径检查\n",
    "# ==============================================================================\n",
    "print(\">>> [DEBUG] 步骤 2: 配置模型和文件路径...\")\n",
    "\n",
    "YOLO_MODEL_PATH = '/root/autodl-tmp/epoch30.pt'\n",
    "METRIC3D_MODEL_PATH = '/root/autodl-tmp/weights/metric_depth_vit_large_800k.pth'\n",
    "METRIC3D_CONFIG_PATH = '/root/autodl-tmp/Metric3D/mono/configs/HourglassDecoder/vit.raft5.large.py'\n",
    "INPUT_VIDEO_PATH = '/root/autodl-tmp/0000.mp4'\n",
    "OUTPUT_VIDEO_PATH = '/root/autodl-tmp/output_video_gmm_filtered.mp4' # <-- 修改输出文件名\n",
    "TRACKER_CONFIG_PATH = '/root/autodl-tmp/bytetrack.yaml'\n",
    "\n",
    "\n",
    "paths_to_check = {\n",
    "    \"YOLOv8 权重\": YOLO_MODEL_PATH,\n",
    "    \"Metric3D 权重\": METRIC3D_MODEL_PATH,\n",
    "    \"Metric3D 配置\": METRIC3D_CONFIG_PATH,\n",
    "    \"输入视频\": INPUT_VIDEO_PATH,\n",
    "    \"跟踪器配置\": TRACKER_CONFIG_PATH,\n",
    "}\n",
    "all_paths_ok = True\n",
    "for name, path in paths_to_check.items():\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"!!! [ERROR] 路径检查失败: {name} 文件未找到于 '{path}'\")\n",
    "        all_paths_ok = False\n",
    "if not all_paths_ok:\n",
    "    raise FileNotFoundError(\"一个或多个关键文件路径无效。\")\n",
    "else:\n",
    "    print(\">>> [DEBUG] 所有文件路径检查通过。\")\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\">>> [DEBUG] 将要使用的设备: {DEVICE}\")\n",
    "\n",
    "print(\">>> [DEBUG] 步骤 2: 配置完成。\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. 模型加载\n",
    "# ==============================================================================\n",
    "print(\">>> [DEBUG] 步骤 3: 开始加载深度学习模型...\")\n",
    "try:\n",
    "    yolo_model = YOLO(YOLO_MODEL_PATH)\n",
    "    TARGET_CLASS_NAME = 'Car'\n",
    "    TARGET_CLASS_ID = [k for k, v in yolo_model.names.items() if v == TARGET_CLASS_NAME][0]\n",
    "    print(f\">>> [INFO] 目标类别 '{TARGET_CLASS_NAME}' 已找到, ID为: {TARGET_CLASS_ID}\")\n",
    "except Exception as e:\n",
    "    print(f\"!!! [ERROR] 加载 YOLOv8 模型或查找类别ID时失败: {e}\")\n",
    "    raise\n",
    "\n",
    "try:\n",
    "    cfg = Config.fromfile(METRIC3D_CONFIG_PATH)\n",
    "    cfg.model.backbone.use_mask_token = False\n",
    "    metric3d_model = MonoDepthModel(cfg).to(DEVICE)\n",
    "    checkpoint = torch.load(METRIC3D_MODEL_PATH, map_location=DEVICE)\n",
    "    state_dict = checkpoint.get('model_state_dict', checkpoint.get('model', checkpoint))\n",
    "    metric3d_model.load_state_dict(state_dict, strict=False)\n",
    "    metric3d_model.eval()\n",
    "    print(\">>> [SUCCESS] Metric3Dv2 模型加载并移动到 GPU 成功！\")\n",
    "except Exception as e:\n",
    "    print(f\"!!! [FATAL ERROR] 加载 Metric3Dv2 模型时出错: {e}\")\n",
    "    raise\n",
    "\n",
    "print(\">>> [DEBUG] 步骤 3: 所有模型加载完成。\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 4. 视频处理主函数\n",
    "# ==============================================================================\n",
    "print(\">>> [DEBUG] 步骤 4: 定义视频处理函数...\")\n",
    "def process_video_debug(input_path, output_path):\n",
    "    print(\"\\n--- 开始视频处理 ---\")\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    metric3d_input_size = (cfg.data_basic['vit_size'][1], cfg.data_basic['vit_size'][0])\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "    \n",
    "    print(f\">>> [INFO] 输入视频信息: {width}x{height} @ {fps:.2f} FPS, 共 {total_frames} 帧。\")\n",
    "\n",
    "    kalman_filters = {}\n",
    "\n",
    "    with tqdm(total=total_frames, desc=\"视频处理进度\") as pbar:\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            track_results = yolo_model.track(frame, persist=True, verbose=False, tracker=TRACKER_CONFIG_PATH, classes=[TARGET_CLASS_ID])\n",
    "            annotated_frame = frame.copy()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                rgb_frame_resized = cv2.resize(rgb_frame, metric3d_input_size)\n",
    "                rgb_torch = torch.from_numpy(rgb_frame_resized).permute(2, 0, 1).unsqueeze(0).float().to(DEVICE) / 255.0\n",
    "                pred_output = metric3d_model(data={'input': rgb_torch})\n",
    "                pred_depth_np = pred_output[0].squeeze().cpu().numpy()\n",
    "                pred_depth_resized = cv2.resize(pred_depth_np, (width, height)).astype(np.float32)\n",
    "                pred_depth_filtered = cv2.bilateralFilter(pred_depth_resized, d=5, sigmaColor=0.2, sigmaSpace=15)\n",
    "\n",
    "            boxes = track_results[0].boxes.xyxy.cpu().numpy()\n",
    "            track_ids = track_results[0].boxes.id.int().cpu().tolist() if track_results[0].boxes.id is not None else []\n",
    "            active_track_ids = set()\n",
    "\n",
    "            if len(track_ids) > 0:\n",
    "                for box, track_id in zip(boxes, track_ids):\n",
    "                    active_track_ids.add(track_id)\n",
    "                    x1, y1, x2, y2 = map(int, box)\n",
    "                    \n",
    "                    cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                    \n",
    "                    # --- 修复语法错误：恢复ROI计算逻辑 ---\n",
    "                    box_w, box_h = x2 - x1, y2 - y1\n",
    "                    roi_w, roi_h = int(box_w * 0.5), int(box_h * 0.5)\n",
    "                    roi_x1 = max(x1 + (box_w - roi_w) // 2, 0)\n",
    "                    roi_y1 = max(y1 + (box_h - roi_h) // 2, 0)\n",
    "                    roi_x2 = min(roi_x1 + roi_w, width)\n",
    "                    roi_y2 = min(roi_y1 + roi_h, height)\n",
    "                    # --- 修复结束 ---\n",
    "\n",
    "                    depth_roi = pred_depth_filtered[roi_y1:roi_y2, roi_x1:roi_x2]\n",
    "                    \n",
    "                    observed_depth = 0.0\n",
    "                    if depth_roi.size > 10: # GMM需要一定数量的点才能可靠工作\n",
    "                        # ============================================================\n",
    "                        # === 核心改进: 使用 GMM + BIC 动态寻找最佳深度 ===\n",
    "                        # ============================================================\n",
    "                        try:\n",
    "                            pixels = depth_roi.flatten().reshape(-1, 1)\n",
    "                            \n",
    "                            # 1. 自动寻找最佳聚类数量 (1, 2, or 3)\n",
    "                            n_components_range = range(1, 4)\n",
    "                            lowest_bic = np.infty\n",
    "                            best_gmm = None\n",
    "                            for n_components in n_components_range:\n",
    "                                gmm = GaussianMixture(n_components=n_components, random_state=0)\n",
    "                                gmm.fit(pixels)\n",
    "                                bic_score = gmm.bic(pixels)\n",
    "                                if bic_score < lowest_bic:\n",
    "                                    lowest_bic = bic_score\n",
    "                                    best_gmm = gmm\n",
    "                            \n",
    "                            cluster_means = best_gmm.means_.flatten()\n",
    "                            \n",
    "                            # --- 修正与卡尔曼滤波的交互逻辑 ---\n",
    "                            if track_id in kalman_filters:\n",
    "                                kf = kalman_filters[track_id]\n",
    "                                # 步骤A: 首先, 基于上一状态进行预测\n",
    "                                kf.predict()\n",
    "                                predicted_depth = kf.x[0] # 预测出的当前深度\n",
    "                                \n",
    "                                # 步骤B: 然后, 在GMM找到的多个聚类中心里, 找到与预测值最接近的一个\n",
    "                                observed_depth = min(cluster_means, key=lambda x: abs(x - predicted_depth))\n",
    "                            else:\n",
    "                                # 如果是新目标, 没有历史信息, 只能假设最近的物体是目标\n",
    "                                observed_depth = min(cluster_means)\n",
    "\n",
    "                        except Exception:\n",
    "                            # 如果GMM失败, 回退到均值\n",
    "                            observed_depth = np.mean(depth_roi)\n",
    "                        # ============================================================\n",
    "                    elif depth_roi.size > 0:\n",
    "                        observed_depth = np.mean(depth_roi)\n",
    "                    else:\n",
    "                        continue\n",
    "                        \n",
    "                    if observed_depth <= 0:\n",
    "                        continue\n",
    "\n",
    "                    if track_id not in kalman_filters:\n",
    "                        # 初始化新的卡尔曼滤波器\n",
    "                        kf = KalmanFilter(dim_x=2, dim_z=1)\n",
    "                        kf.x = np.array([observed_depth, 0.])\n",
    "                        kf.F = np.array([[1., 1.], [0., 1.]])\n",
    "                        kf.H = np.array([[1., 0.]])\n",
    "                        kf.P *= 100.\n",
    "                        kf.R = 5 # GMM的结果更可信, 可以适当调低测量噪声\n",
    "                        kf.Q = 0.1\n",
    "                        kalman_filters[track_id] = kf\n",
    "                    else:\n",
    "                        # 对于已有目标, predict已在上面完成, 这里直接update\n",
    "                        kf = kalman_filters[track_id]\n",
    "                        kf.update(observed_depth)\n",
    "\n",
    "                    smoothed_depth = kf.x[0]\n",
    "                    \n",
    "                    depth_text = f\"ID:{track_id} D:{smoothed_depth:.2f}m\"\n",
    "                    (text_w, text_h), _ = cv2.getTextSize(depth_text, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)\n",
    "                    cv2.rectangle(annotated_frame, (x1, y1 - 25), (x1 + text_w + 5, y1 - 5), (0, 100, 0), -1)\n",
    "                    cv2.putText(annotated_frame, depth_text, (x1 + 2, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "            \n",
    "            inactive_ids = set(kalman_filters.keys()) - active_track_ids\n",
    "            for inactive_id in inactive_ids:\n",
    "                del kalman_filters[inactive_id]\n",
    "\n",
    "            out.write(annotated_frame)\n",
    "            pbar.update(1)\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(f\"\\n--- 视频处理完成！ ---\")\n",
    "    print(f\">>> [SUCCESS] 输出视频已成功保存到: {output_path}\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 5. 运行主程序\n",
    "# ==============================================================================\n",
    "print(\">>> [DEBUG] 步骤 5: 开始执行主程序...\")\n",
    "try:\n",
    "    process_video_debug(INPUT_VIDEO_PATH, OUTPUT_VIDEO_PATH)\n",
    "except Exception as e:\n",
    "    print(f\"!!! [FATAL ERROR] 在视频处理过程中发生严重错误: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "print(\">>> [DEBUG] 步骤 5: 主程序执行完毕。\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cfe51da-339e-4b32-809e-6b64ae665572",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [DEBUG] 步骤 0: 检查关键库版本...\n",
      ">>> [INFO] mmcv version: 1.7.2\n",
      ">>> [INFO] timm version: 0.6.12\n",
      ">>> [INFO] filterpy 和 scikit-learn (GMM) 库已成功导入。\n",
      ">>> [DEBUG] 步骤 0: 检查完成。\n",
      "============================================================\n",
      "\n",
      ">>> [DEBUG] 步骤 1: 开始导入核心库...\n",
      ">>> [DEBUG] 核心库 cv2, torch, numpy, ultralytics, tqdm, mmcv.Config 导入成功。\n",
      ">>> [DEBUG] Metric3D 模块 'DepthModel' (作为 MonoDepthModel) 导入成功。\n",
      ">>> [DEBUG] 步骤 1: 所有库导入完成。\n",
      "============================================================\n",
      "\n",
      ">>> [DEBUG] 步骤 2: 配置模型和文件路径...\n",
      ">>> [DEBUG] 所有文件路径检查通过。\n",
      ">>> [DEBUG] 将要使用的设备: cuda\n",
      ">>> [DEBUG] 步骤 2: 配置完成。\n",
      "============================================================\n",
      "\n",
      ">>> [DEBUG] 步骤 3: 开始加载深度学习模型...\n",
      ">>> [INFO] 目标类别 'Car' 已找到, ID为: 0\n",
      ">>> [SUCCESS] Metric3Dv2 模型加载并移动到 GPU 成功！\n",
      ">>> [DEBUG] 步骤 3: 所有模型加载完成。\n",
      "============================================================\n",
      "\n",
      ">>> [DEBUG] 步骤 4: 定义视频处理函数...\n",
      ">>> [DEBUG] 步骤 5: 开始执行主程序...\n",
      "\n",
      "--- 开始视频处理 ---\n",
      ">>> [INFO] 输入视频信息: 1242x374 @ 1.00 FPS, 共 154 帧。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "视频处理进度: 100%|██████████| 154/154 [01:25<00:00,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 视频处理完成！ ---\n",
      ">>> [SUCCESS] 输出视频已成功保存到: /root/autodl-tmp/output_video_gmm_filtered.mp4\n",
      ">>> [DEBUG] 步骤 5: 主程序执行完毕。\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# 0. 关键依赖库检查 (用于调试)\n",
    "# ==============================================================================\n",
    "print(\">>> [DEBUG] 步骤 0: 检查关键库版本...\")\n",
    "try:\n",
    "    import mmcv\n",
    "    import timm\n",
    "    from filterpy.kalman import KalmanFilter\n",
    "    # --- 导入 GMM ---\n",
    "    from sklearn.mixture import GaussianMixture\n",
    "    print(f\">>> [INFO] mmcv version: {mmcv.__version__}\")\n",
    "    print(f\">>> [INFO] timm version: {timm.__version__}\")\n",
    "    print(\">>> [INFO] filterpy 和 scikit-learn (GMM) 库已成功导入。\")\n",
    "except ImportError as e:\n",
    "    print(f\"!!! [ERROR] 缺少核心库: {e}\")\n",
    "    print(\"!!! [HINT] 请确保已安装 filterpy (pip install filterpy) 和 scikit-learn (pip install scikit-learn)。\")\n",
    "    raise\n",
    "print(\">>> [DEBUG] 步骤 0: 检查完成。\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. 导入必要的库\n",
    "# ==============================================================================\n",
    "print(\">>> [DEBUG] 步骤 1: 开始导入核心库...\")\n",
    "try:\n",
    "    import cv2\n",
    "    import torch\n",
    "    import numpy as np\n",
    "    from ultralytics import YOLO\n",
    "    import sys\n",
    "    import os\n",
    "    from tqdm import tqdm\n",
    "    from mmcv import Config\n",
    "    print(\">>> [DEBUG] 核心库 cv2, torch, numpy, ultralytics, tqdm, mmcv.Config 导入成功。\")\n",
    "except ImportError as e:\n",
    "    print(f\"!!! [ERROR] 导入核心库失败: {e}\")\n",
    "    raise\n",
    "\n",
    "# --- 导入 Metric3D 相关的模块 ---\n",
    "METRIC3D_PATH = '/root/autodl-tmp/Metric3D'\n",
    "if METRIC3D_PATH not in sys.path:\n",
    "    sys.path.insert(0, METRIC3D_PATH)\n",
    "\n",
    "try:\n",
    "    from mono.model.monodepth_model import DepthModel as MonoDepthModel\n",
    "    print(\">>> [DEBUG] Metric3D 模块 'DepthModel' (作为 MonoDepthModel) 导入成功。\")\n",
    "except ImportError as e:\n",
    "    print(f\"!!! [ERROR] 从 Metric3D 导入模块失败: {e}\")\n",
    "    raise\n",
    "\n",
    "print(\">>> [DEBUG] 步骤 1: 所有库导入完成。\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. 配置区域与路径检查\n",
    "# ==============================================================================\n",
    "print(\">>> [DEBUG] 步骤 2: 配置模型和文件路径...\")\n",
    "\n",
    "YOLO_MODEL_PATH = '/root/autodl-tmp/epoch30.pt'\n",
    "METRIC3D_MODEL_PATH = '/root/autodl-tmp/weights/metric_depth_vit_large_800k.pth'\n",
    "METRIC3D_CONFIG_PATH = '/root/autodl-tmp/Metric3D/mono/configs/HourglassDecoder/vit.raft5.large.py'\n",
    "INPUT_VIDEO_PATH = '/root/autodl-tmp/0000.mp4'\n",
    "OUTPUT_VIDEO_PATH = '/root/autodl-tmp/output_video_gmm_filtered.mp4' # <-- 修改输出文件名\n",
    "TRACKER_CONFIG_PATH = '/root/autodl-tmp/bytetrack.yaml'\n",
    "\n",
    "\n",
    "paths_to_check = {\n",
    "    \"YOLOv8 权重\": YOLO_MODEL_PATH,\n",
    "    \"Metric3D 权重\": METRIC3D_MODEL_PATH,\n",
    "    \"Metric3D 配置\": METRIC3D_CONFIG_PATH,\n",
    "    \"输入视频\": INPUT_VIDEO_PATH,\n",
    "    \"跟踪器配置\": TRACKER_CONFIG_PATH,\n",
    "}\n",
    "all_paths_ok = True\n",
    "for name, path in paths_to_check.items():\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"!!! [ERROR] 路径检查失败: {name} 文件未找到于 '{path}'\")\n",
    "        all_paths_ok = False\n",
    "if not all_paths_ok:\n",
    "    raise FileNotFoundError(\"一个或多个关键文件路径无效。\")\n",
    "else:\n",
    "    print(\">>> [DEBUG] 所有文件路径检查通过。\")\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\">>> [DEBUG] 将要使用的设备: {DEVICE}\")\n",
    "\n",
    "print(\">>> [DEBUG] 步骤 2: 配置完成。\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. 模型加载\n",
    "# ==============================================================================\n",
    "print(\">>> [DEBUG] 步骤 3: 开始加载深度学习模型...\")\n",
    "try:\n",
    "    yolo_model = YOLO(YOLO_MODEL_PATH)\n",
    "    TARGET_CLASS_NAME = 'Car'\n",
    "    TARGET_CLASS_ID = [k for k, v in yolo_model.names.items() if v == TARGET_CLASS_NAME][0]\n",
    "    print(f\">>> [INFO] 目标类别 '{TARGET_CLASS_NAME}' 已找到, ID为: {TARGET_CLASS_ID}\")\n",
    "except Exception as e:\n",
    "    print(f\"!!! [ERROR] 加载 YOLOv8 模型或查找类别ID时失败: {e}\")\n",
    "    raise\n",
    "\n",
    "try:\n",
    "    cfg = Config.fromfile(METRIC3D_CONFIG_PATH)\n",
    "    cfg.model.backbone.use_mask_token = False\n",
    "    metric3d_model = MonoDepthModel(cfg).to(DEVICE)\n",
    "    checkpoint = torch.load(METRIC3D_MODEL_PATH, map_location=DEVICE)\n",
    "    state_dict = checkpoint.get('model_state_dict', checkpoint.get('model', checkpoint))\n",
    "    metric3d_model.load_state_dict(state_dict, strict=False)\n",
    "    metric3d_model.eval()\n",
    "    print(\">>> [SUCCESS] Metric3Dv2 模型加载并移动到 GPU 成功！\")\n",
    "except Exception as e:\n",
    "    print(f\"!!! [FATAL ERROR] 加载 Metric3Dv2 模型时出错: {e}\")\n",
    "    raise\n",
    "\n",
    "print(\">>> [DEBUG] 步骤 3: 所有模型加载完成。\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 4. 视频处理主函数\n",
    "# ==============================================================================\n",
    "print(\">>> [DEBUG] 步骤 4: 定义视频处理函数...\")\n",
    "def process_video_debug(input_path, output_path):\n",
    "    print(\"\\n--- 开始视频处理 ---\")\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    metric3d_input_size = (cfg.data_basic['vit_size'][1], cfg.data_basic['vit_size'][0])\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "    \n",
    "    print(f\">>> [INFO] 输入视频信息: {width}x{height} @ {fps:.2f} FPS, 共 {total_frames} 帧。\")\n",
    "\n",
    "    kalman_filters = {}\n",
    "\n",
    "    with tqdm(total=total_frames, desc=\"视频处理进度\") as pbar:\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            track_results = yolo_model.track(frame, persist=True, verbose=False, tracker=TRACKER_CONFIG_PATH, classes=[TARGET_CLASS_ID])\n",
    "            annotated_frame = frame.copy()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                rgb_frame_resized = cv2.resize(rgb_frame, metric3d_input_size)\n",
    "                rgb_torch = torch.from_numpy(rgb_frame_resized).permute(2, 0, 1).unsqueeze(0).float().to(DEVICE) / 255.0\n",
    "                pred_output = metric3d_model(data={'input': rgb_torch})\n",
    "                pred_depth_np = pred_output[0].squeeze().cpu().numpy()\n",
    "                pred_depth_resized = cv2.resize(pred_depth_np, (width, height)).astype(np.float32)\n",
    "                pred_depth_filtered = cv2.bilateralFilter(pred_depth_resized, d=5, sigmaColor=0.2, sigmaSpace=15)\n",
    "\n",
    "            boxes = track_results[0].boxes.xyxy.cpu().numpy()\n",
    "            track_ids = track_results[0].boxes.id.int().cpu().tolist() if track_results[0].boxes.id is not None else []\n",
    "            active_track_ids = set()\n",
    "\n",
    "            if len(track_ids) > 0:\n",
    "                for box, track_id in zip(boxes, track_ids):\n",
    "                    active_track_ids.add(track_id)\n",
    "                    x1, y1, x2, y2 = map(int, box)\n",
    "                    \n",
    "                    cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                    \n",
    "                    # --- 修复语法错误：恢复ROI计算逻辑 ---\n",
    "                    box_w, box_h = x2 - x1, y2 - y1\n",
    "                    roi_w, roi_h = int(box_w * 0.5), int(box_h * 0.5)\n",
    "                    roi_x1 = max(x1 + (box_w - roi_w) // 2, 0)\n",
    "                    roi_y1 = max(y1 + (box_h - roi_h) // 2, 0)\n",
    "                    roi_x2 = min(roi_x1 + roi_w, width)\n",
    "                    roi_y2 = min(roi_y1 + roi_h, height)\n",
    "                    # --- 修复结束 ---\n",
    "\n",
    "                    depth_roi = pred_depth_filtered[roi_y1:roi_y2, roi_x1:roi_x2]\n",
    "                    \n",
    "                    observed_depth = 0.0\n",
    "                    if depth_roi.size > 10: # GMM需要一定数量的点才能可靠工作\n",
    "                        # ============================================================\n",
    "                        # === 核心改进: 使用 GMM + BIC 动态寻找最佳深度 ===\n",
    "                        # ============================================================\n",
    "                        try:\n",
    "                            pixels = depth_roi.flatten().reshape(-1, 1)\n",
    "                            \n",
    "                            # 1. 自动寻找最佳聚类数量 (1, 2, or 3)\n",
    "                            n_components_range = range(1, 4)\n",
    "                            lowest_bic = np.infty\n",
    "                            best_gmm = None\n",
    "                            for n_components in n_components_range:\n",
    "                                gmm = GaussianMixture(n_components=n_components, random_state=0)\n",
    "                                gmm.fit(pixels)\n",
    "                                bic_score = gmm.bic(pixels)\n",
    "                                if bic_score < lowest_bic:\n",
    "                                    lowest_bic = bic_score\n",
    "                                    best_gmm = gmm\n",
    "                            \n",
    "                            cluster_means = best_gmm.means_.flatten()\n",
    "                            \n",
    "                            # --- 修正与卡尔曼滤波的交互逻辑 ---\n",
    "                            if track_id in kalman_filters:\n",
    "                                kf = kalman_filters[track_id]\n",
    "                                # 步骤A: 首先, 基于上一状态进行预测\n",
    "                                kf.predict()\n",
    "                                predicted_depth = kf.x[0] # 预测出的当前深度\n",
    "                                \n",
    "                                # 步骤B: 然后, 在GMM找到的多个聚类中心里, 找到与预测值最接近的一个\n",
    "                                observed_depth = min(cluster_means, key=lambda x: abs(x - predicted_depth))\n",
    "                            else:\n",
    "                                # 如果是新目标, 没有历史信息, 只能假设最近的物体是目标\n",
    "                                observed_depth = min(cluster_means)\n",
    "\n",
    "                        except Exception:\n",
    "                            # 如果GMM失败, 回退到均值\n",
    "                            observed_depth = np.mean(depth_roi)\n",
    "                        # ============================================================\n",
    "                    elif depth_roi.size > 0:\n",
    "                        observed_depth = np.mean(depth_roi)\n",
    "                    else:\n",
    "                        continue\n",
    "                        \n",
    "                    if observed_depth <= 0:\n",
    "                        continue\n",
    "\n",
    "                    if track_id not in kalman_filters:\n",
    "                        # 初始化新的卡尔曼滤波器\n",
    "                        kf = KalmanFilter(dim_x=2, dim_z=1)\n",
    "                        kf.x = np.array([observed_depth, 0.])\n",
    "                        kf.F = np.array([[1., 1.], [0., 1.]])\n",
    "                        kf.H = np.array([[1., 0.]])\n",
    "                        kf.P *= 100.\n",
    "                        kf.R = 5 # GMM的结果更可信, 可以适当调低测量噪声\n",
    "                        kf.Q = 0.1\n",
    "                        kalman_filters[track_id] = kf\n",
    "                    else:\n",
    "                        # 对于已有目标, predict已在上面完成, 这里直接update\n",
    "                        kf = kalman_filters[track_id]\n",
    "                        kf.update(observed_depth)\n",
    "\n",
    "                    smoothed_depth = kf.x[0]\n",
    "                    \n",
    "                    depth_text = f\"ID:{track_id} D:{smoothed_depth:.2f}m\"\n",
    "                    (text_w, text_h), _ = cv2.getTextSize(depth_text, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)\n",
    "                    cv2.rectangle(annotated_frame, (x1, y1 - 25), (x1 + text_w + 5, y1 - 5), (0, 100, 0), -1)\n",
    "                    cv2.putText(annotated_frame, depth_text, (x1 + 2, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "            \n",
    "            inactive_ids = set(kalman_filters.keys()) - active_track_ids\n",
    "            for inactive_id in inactive_ids:\n",
    "                del kalman_filters[inactive_id]\n",
    "\n",
    "            out.write(annotated_frame)\n",
    "            pbar.update(1)\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(f\"\\n--- 视频处理完成！ ---\")\n",
    "    print(f\">>> [SUCCESS] 输出视频已成功保存到: {output_path}\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 5. 运行主程序\n",
    "# ==============================================================================\n",
    "print(\">>> [DEBUG] 步骤 5: 开始执行主程序...\")\n",
    "try:\n",
    "    process_video_debug(INPUT_VIDEO_PATH, OUTPUT_VIDEO_PATH)\n",
    "except Exception as e:\n",
    "    print(f\"!!! [FATAL ERROR] 在视频处理过程中发生严重错误: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "print(\">>> [DEBUG] 步骤 5: 主程序执行完毕。\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18227d7d-2dc3-448a-8776-f394a39d6392",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [DEBUG] 步骤 0: 检查关键库版本...\n",
      ">>> [INFO] mmcv version: 1.7.2\n",
      ">>> [INFO] timm version: 0.6.12\n",
      ">>> [INFO] filterpy 和 scikit-learn (GMM) 库已成功导入。\n",
      ">>> [DEBUG] 步骤 0: 检查完成。\n",
      "============================================================\n",
      "\n",
      ">>> [DEBUG] 步骤 1: 开始导入核心库...\n",
      ">>> [DEBUG] 核心库 cv2, torch, numpy, ultralytics, tqdm, mmcv.Config 导入成功。\n",
      ">>> [DEBUG] Metric3D 模块 'DepthModel' (作为 MonoDepthModel) 导入成功。\n",
      ">>> [DEBUG] 步骤 1: 所有库导入完成。\n",
      "============================================================\n",
      "\n",
      ">>> [DEBUG] 步骤 2: 配置模型和文件路径...\n",
      ">>> [DEBUG] 所有文件路径检查通过。\n",
      ">>> [DEBUG] 将要使用的设备: cuda\n",
      ">>> [DEBUG] 步骤 2: 配置完成。\n",
      "============================================================\n",
      "\n",
      ">>> [DEBUG] 步骤 3: 开始加载深度学习模型...\n",
      ">>> [INFO] 目标类别 'Car' 已找到, ID为: 0\n",
      ">>> [SUCCESS] Metric3Dv2 模型加载并移动到 GPU 成功！\n",
      ">>> [DEBUG] 步骤 3: 所有模型加载完成。\n",
      "============================================================\n",
      "\n",
      ">>> [DEBUG] 步骤 4: 定义视频处理函数...\n",
      ">>> [DEBUG] 步骤 5: 开始执行主程序...\n",
      "\n",
      "--- 开始视频处理 ---\n",
      ">>> [INFO] 输入视频信息: 1242x374 @ 1.00 FPS, 共 154 帧。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "视频处理进度: 100%|██████████| 154/154 [01:25<00:00,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 视频处理完成！ ---\n",
      ">>> [SUCCESS] 输出视频已成功保存到: /root/autodl-tmp/output_video_gmm_filtered.mp4\n",
      ">>> [DEBUG] 步骤 5: 主程序执行完毕。\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# 0. 关键依赖库检查 (用于调试)\n",
    "# ==============================================================================\n",
    "print(\">>> [DEBUG] 步骤 0: 检查关键库版本...\")\n",
    "try:\n",
    "    import mmcv\n",
    "    import timm\n",
    "    from filterpy.kalman import KalmanFilter\n",
    "    # --- 导入 GMM ---\n",
    "    from sklearn.mixture import GaussianMixture\n",
    "    print(f\">>> [INFO] mmcv version: {mmcv.__version__}\")\n",
    "    print(f\">>> [INFO] timm version: {timm.__version__}\")\n",
    "    print(\">>> [INFO] filterpy 和 scikit-learn (GMM) 库已成功导入。\")\n",
    "except ImportError as e:\n",
    "    print(f\"!!! [ERROR] 缺少核心库: {e}\")\n",
    "    print(\"!!! [HINT] 请确保已安装 filterpy (pip install filterpy) 和 scikit-learn (pip install scikit-learn)。\")\n",
    "    raise\n",
    "print(\">>> [DEBUG] 步骤 0: 检查完成。\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. 导入必要的库\n",
    "# ==============================================================================\n",
    "print(\">>> [DEBUG] 步骤 1: 开始导入核心库...\")\n",
    "try:\n",
    "    import cv2\n",
    "    import torch\n",
    "    import numpy as np\n",
    "    from ultralytics import YOLO\n",
    "    import sys\n",
    "    import os\n",
    "    from tqdm import tqdm\n",
    "    from mmcv import Config\n",
    "    print(\">>> [DEBUG] 核心库 cv2, torch, numpy, ultralytics, tqdm, mmcv.Config 导入成功。\")\n",
    "except ImportError as e:\n",
    "    print(f\"!!! [ERROR] 导入核心库失败: {e}\")\n",
    "    raise\n",
    "\n",
    "# --- 导入 Metric3D 相关的模块 ---\n",
    "METRIC3D_PATH = '/root/autodl-tmp/Metric3D'\n",
    "if METRIC3D_PATH not in sys.path:\n",
    "    sys.path.insert(0, METRIC3D_PATH)\n",
    "\n",
    "try:\n",
    "    from mono.model.monodepth_model import DepthModel as MonoDepthModel\n",
    "    print(\">>> [DEBUG] Metric3D 模块 'DepthModel' (作为 MonoDepthModel) 导入成功。\")\n",
    "except ImportError as e:\n",
    "    print(f\"!!! [ERROR] 从 Metric3D 导入模块失败: {e}\")\n",
    "    raise\n",
    "\n",
    "print(\">>> [DEBUG] 步骤 1: 所有库导入完成。\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. 配置区域与路径检查\n",
    "# ==============================================================================\n",
    "print(\">>> [DEBUG] 步骤 2: 配置模型和文件路径...\")\n",
    "\n",
    "YOLO_MODEL_PATH = '/root/autodl-tmp/epoch30.pt'\n",
    "METRIC3D_MODEL_PATH = '/root/autodl-tmp/weights/metric_depth_vit_large_800k.pth'\n",
    "METRIC3D_CONFIG_PATH = '/root/autodl-tmp/Metric3D/mono/configs/HourglassDecoder/vit.raft5.large.py'\n",
    "INPUT_VIDEO_PATH = '/root/autodl-tmp/0000.mp4'\n",
    "OUTPUT_VIDEO_PATH = '/root/autodl-tmp/output_video_gmm_filtered.mp4' # <-- 修改输出文件名\n",
    "TRACKER_CONFIG_PATH = '/root/autodl-tmp/bytetrack.yaml'\n",
    "\n",
    "\n",
    "paths_to_check = {\n",
    "    \"YOLOv8 权重\": YOLO_MODEL_PATH,\n",
    "    \"Metric3D 权重\": METRIC3D_MODEL_PATH,\n",
    "    \"Metric3D 配置\": METRIC3D_CONFIG_PATH,\n",
    "    \"输入视频\": INPUT_VIDEO_PATH,\n",
    "    \"跟踪器配置\": TRACKER_CONFIG_PATH,\n",
    "}\n",
    "all_paths_ok = True\n",
    "for name, path in paths_to_check.items():\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"!!! [ERROR] 路径检查失败: {name} 文件未找到于 '{path}'\")\n",
    "        all_paths_ok = False\n",
    "if not all_paths_ok:\n",
    "    raise FileNotFoundError(\"一个或多个关键文件路径无效。\")\n",
    "else:\n",
    "    print(\">>> [DEBUG] 所有文件路径检查通过。\")\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\">>> [DEBUG] 将要使用的设备: {DEVICE}\")\n",
    "\n",
    "print(\">>> [DEBUG] 步骤 2: 配置完成。\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. 模型加载\n",
    "# ==============================================================================\n",
    "print(\">>> [DEBUG] 步骤 3: 开始加载深度学习模型...\")\n",
    "try:\n",
    "    yolo_model = YOLO(YOLO_MODEL_PATH)\n",
    "    TARGET_CLASS_NAME = 'Car'\n",
    "    TARGET_CLASS_ID = [k for k, v in yolo_model.names.items() if v == TARGET_CLASS_NAME][0]\n",
    "    print(f\">>> [INFO] 目标类别 '{TARGET_CLASS_NAME}' 已找到, ID为: {TARGET_CLASS_ID}\")\n",
    "except Exception as e:\n",
    "    print(f\"!!! [ERROR] 加载 YOLOv8 模型或查找类别ID时失败: {e}\")\n",
    "    raise\n",
    "\n",
    "try:\n",
    "    cfg = Config.fromfile(METRIC3D_CONFIG_PATH)\n",
    "    cfg.model.backbone.use_mask_token = False\n",
    "    metric3d_model = MonoDepthModel(cfg).to(DEVICE)\n",
    "    checkpoint = torch.load(METRIC3D_MODEL_PATH, map_location=DEVICE)\n",
    "    state_dict = checkpoint.get('model_state_dict', checkpoint.get('model', checkpoint))\n",
    "    metric3d_model.load_state_dict(state_dict, strict=False)\n",
    "    metric3d_model.eval()\n",
    "    print(\">>> [SUCCESS] Metric3Dv2 模型加载并移动到 GPU 成功！\")\n",
    "except Exception as e:\n",
    "    print(f\"!!! [FATAL ERROR] 加载 Metric3Dv2 模型时出错: {e}\")\n",
    "    raise\n",
    "\n",
    "print(\">>> [DEBUG] 步骤 3: 所有模型加载完成。\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 4. 视频处理主函数\n",
    "# ==============================================================================\n",
    "print(\">>> [DEBUG] 步骤 4: 定义视频处理函数...\")\n",
    "def process_video_debug(input_path, output_path):\n",
    "    print(\"\\n--- 开始视频处理 ---\")\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    metric3d_input_size = (cfg.data_basic['vit_size'][1], cfg.data_basic['vit_size'][0])\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "    \n",
    "    print(f\">>> [INFO] 输入视频信息: {width}x{height} @ {fps:.2f} FPS, 共 {total_frames} 帧。\")\n",
    "\n",
    "    kalman_filters = {}\n",
    "\n",
    "    with tqdm(total=total_frames, desc=\"视频处理进度\") as pbar:\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            track_results = yolo_model.track(frame, persist=True, verbose=False, tracker=TRACKER_CONFIG_PATH, classes=[TARGET_CLASS_ID])\n",
    "            annotated_frame = frame.copy()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                rgb_frame_resized = cv2.resize(rgb_frame, metric3d_input_size)\n",
    "                rgb_torch = torch.from_numpy(rgb_frame_resized).permute(2, 0, 1).unsqueeze(0).float().to(DEVICE) / 255.0\n",
    "                pred_output = metric3d_model(data={'input': rgb_torch})\n",
    "                pred_depth_np = pred_output[0].squeeze().cpu().numpy()\n",
    "                pred_depth_resized = cv2.resize(pred_depth_np, (width, height)).astype(np.float32)\n",
    "                pred_depth_filtered = cv2.bilateralFilter(pred_depth_resized, d=5, sigmaColor=0.2, sigmaSpace=15)\n",
    "\n",
    "            boxes = track_results[0].boxes.xyxy.cpu().numpy()\n",
    "            track_ids = track_results[0].boxes.id.int().cpu().tolist() if track_results[0].boxes.id is not None else []\n",
    "            active_track_ids = set()\n",
    "\n",
    "            if len(track_ids) > 0:\n",
    "                for box, track_id in zip(boxes, track_ids):\n",
    "                    active_track_ids.add(track_id)\n",
    "                    x1, y1, x2, y2 = map(int, box)\n",
    "                    \n",
    "                    cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                    \n",
    "                    # --- 修复语法错误：恢复ROI计算逻辑 ---\n",
    "                    box_w, box_h = x2 - x1, y2 - y1\n",
    "                    roi_w, roi_h = int(box_w * 0.5), int(box_h * 0.5)\n",
    "                    roi_x1 = max(x1 + (box_w - roi_w) // 2, 0)\n",
    "                    roi_y1 = max(y1 + (box_h - roi_h) // 2, 0)\n",
    "                    roi_x2 = min(roi_x1 + roi_w, width)\n",
    "                    roi_y2 = min(roi_y1 + roi_h, height)\n",
    "                    # --- 修复结束 ---\n",
    "\n",
    "                    depth_roi = pred_depth_filtered[roi_y1:roi_y2, roi_x1:roi_x2]\n",
    "                    \n",
    "                    observed_depth = 0.0\n",
    "                    if depth_roi.size > 10: # GMM需要一定数量的点才能可靠工作\n",
    "                        # ============================================================\n",
    "                        # === 核心改进: 使用 GMM + BIC 动态寻找最佳深度 ===\n",
    "                        # ============================================================\n",
    "                        try:\n",
    "                            pixels = depth_roi.flatten().reshape(-1, 1)\n",
    "                            \n",
    "                            # 1. 自动寻找最佳聚类数量 (1, 2, or 3)\n",
    "                            n_components_range = range(1, 4)\n",
    "                            lowest_bic = np.infty\n",
    "                            best_gmm = None\n",
    "                            for n_components in n_components_range:\n",
    "                                gmm = GaussianMixture(n_components=n_components, random_state=0)\n",
    "                                gmm.fit(pixels)\n",
    "                                bic_score = gmm.bic(pixels)\n",
    "                                if bic_score < lowest_bic:\n",
    "                                    lowest_bic = bic_score\n",
    "                                    best_gmm = gmm\n",
    "                            \n",
    "                            cluster_means = best_gmm.means_.flatten()\n",
    "                            \n",
    "                            # --- 修正与卡尔曼滤波的交互逻辑 ---\n",
    "                            if track_id in kalman_filters:\n",
    "                                kf = kalman_filters[track_id]\n",
    "                                # 步骤A: 首先, 基于上一状态进行预测\n",
    "                                kf.predict()\n",
    "                                predicted_depth = kf.x[0] # 预测出的当前深度\n",
    "                                \n",
    "                                # 步骤B: 然后, 在GMM找到的多个聚类中心里, 找到与预测值最接近的一个\n",
    "                                observed_depth = min(cluster_means, key=lambda x: abs(x - predicted_depth))\n",
    "                            else:\n",
    "                                # 如果是新目标, 没有历史信息, 只能假设最近的物体是目标\n",
    "                                observed_depth = min(cluster_means)\n",
    "\n",
    "                        except Exception:\n",
    "                            # 如果GMM失败, 回退到均值\n",
    "                            observed_depth = np.mean(depth_roi)\n",
    "                        # ============================================================\n",
    "                    elif depth_roi.size > 0:\n",
    "                        observed_depth = np.mean(depth_roi)\n",
    "                    else:\n",
    "                        continue\n",
    "                        \n",
    "                    if observed_depth <= 0:\n",
    "                        continue\n",
    "\n",
    "                    if track_id not in kalman_filters:\n",
    "                        # 初始化新的卡尔曼滤波器\n",
    "                        kf = KalmanFilter(dim_x=2, dim_z=1)\n",
    "                        kf.x = np.array([observed_depth, 0.])\n",
    "                        kf.F = np.array([[1., 1.], [0., 1.]])\n",
    "                        kf.H = np.array([[1., 0.]])\n",
    "                        kf.P *= 100.\n",
    "                        kf.R = 5 # GMM的结果更可信, 可以适当调低测量噪声\n",
    "                        kf.Q = 0.1\n",
    "                        kalman_filters[track_id] = kf\n",
    "                    else:\n",
    "                        # 对于已有目标, predict已在上面完成, 这里直接update\n",
    "                        kf = kalman_filters[track_id]\n",
    "                        kf.update(observed_depth)\n",
    "\n",
    "                    smoothed_depth = kf.x[0]\n",
    "                    \n",
    "                    depth_text = f\"ID:{track_id} D:{smoothed_depth:.2f}m\"\n",
    "                    (text_w, text_h), _ = cv2.getTextSize(depth_text, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)\n",
    "                    cv2.rectangle(annotated_frame, (x1, y1 - 25), (x1 + text_w + 5, y1 - 5), (0, 100, 0), -1)\n",
    "                    cv2.putText(annotated_frame, depth_text, (x1 + 2, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "            \n",
    "            inactive_ids = set(kalman_filters.keys()) - active_track_ids\n",
    "            for inactive_id in inactive_ids:\n",
    "                del kalman_filters[inactive_id]\n",
    "\n",
    "            out.write(annotated_frame)\n",
    "            pbar.update(1)\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(f\"\\n--- 视频处理完成！ ---\")\n",
    "    print(f\">>> [SUCCESS] 输出视频已成功保存到: {output_path}\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 5. 运行主程序\n",
    "# ==============================================================================\n",
    "print(\">>> [DEBUG] 步骤 5: 开始执行主程序...\")\n",
    "try:\n",
    "    process_video_debug(INPUT_VIDEO_PATH, OUTPUT_VIDEO_PATH)\n",
    "except Exception as e:\n",
    "    print(f\"!!! [FATAL ERROR] 在视频处理过程中发生严重错误: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "print(\">>> [DEBUG] 步骤 5: 主程序执行完毕。\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d2529c-3ef2-45d1-a8ce-7dacae8a09a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mot_depth)",
   "language": "python",
   "name": "mot_depth"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
