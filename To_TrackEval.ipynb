{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727e3d29-2fb7-488f-af0a-2ae981b94e49",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/mot_depth/lib/python3.9/site-packages/torch/utils/cpp_extension.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import packaging  # type: ignore[attr-defined]\n",
      "No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n",
      "/root/miniconda3/envs/mot_depth/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [DEBUG] 步骤 1: 导入 Metric3D 模块...\n",
      ">>> [INFO] Metric3D 模块导入成功。\n",
      "\n",
      ">>> [DEBUG] 步骤 2: 配置模型和文件路径...\n",
      ">>> [INFO] 将要使用的设备: cpu\n",
      "\n",
      ">>> [DEBUG] 步骤 3: 开始加载深度学习模型...\n",
      ">>> [INFO] 目标类别 'Car' ID为: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/mot_depth/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# /root/autodl-tmp/batch_process.py\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from mmcv import Config\n",
    "from types import SimpleNamespace\n",
    "# We still need STrack to reset the ID, but not for format conversion\n",
    "from custom_byte_tracker import ByteTracker, STrack\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. 导入 Metric3D 模块\n",
    "# ==============================================================================\n",
    "print(\">>> [DEBUG] 步骤 1: 导入 Metric3D 模块...\")\n",
    "METRIC3D_PATH = '/root/autodl-tmp/Metric3D'\n",
    "if METRIC3D_PATH not in sys.path:\n",
    "    sys.path.insert(0, METRIC3D_PATH)\n",
    "try:\n",
    "    from mono.model.monodepth_model import DepthModel as MonoDepthModel\n",
    "    print(\">>> [INFO] Metric3D 模块导入成功。\")\n",
    "except ImportError as e:\n",
    "    print(f\"!!! [ERROR] 从 Metric3D 导入模块失败: {e}\")\n",
    "    raise\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. 配置与路径定义\n",
    "# ==============================================================================\n",
    "print(\"\\n>>> [DEBUG] 步骤 2: 配置模型和文件路径...\")\n",
    "YOLO_MODEL_PATH = '/root/autodl-tmp/weights/epoch30.pt'\n",
    "METRIC3D_MODEL_PATH = '/root/autodl-tmp/weights/metric_depth_vit_large_800k.pth'\n",
    "METRIC3D_CONFIG_PATH = '/root/autodl-tmp/Metric3D/mono/configs/HourglassDecoder/vit.raft5.large.py'\n",
    "INPUT_VIDEOS_DIR = '/root/autodl-tmp/kitti_videos/' # <-- MAKE SURE THIS PATH IS CORRECT\n",
    "OUTPUT_EVAL_DIR = '/root/autodl-tmp/eval_outputs/'\n",
    "\n",
    "os.makedirs(OUTPUT_EVAL_DIR, exist_ok=True)\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\">>> [INFO] 将要使用的设备: {DEVICE}\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. 模型加载 (全局加载一次)\n",
    "# ==============================================================================\n",
    "print(\"\\n>>> [DEBUG] 步骤 3: 开始加载深度学习模型...\")\n",
    "try:\n",
    "    yolo_model = YOLO(YOLO_MODEL_PATH)\n",
    "    TARGET_CLASS_NAME = 'Car'\n",
    "    TARGET_CLASS_ID = [k for k, v in yolo_model.names.items() if v == TARGET_CLASS_NAME][0]\n",
    "    print(f\">>> [INFO] 目标类别 '{TARGET_CLASS_NAME}' ID为: {TARGET_CLASS_ID}\")\n",
    "except Exception as e:\n",
    "    print(f\"!!! [ERROR] 加载 YOLOv8 模型失败: {e}\")\n",
    "    raise\n",
    "\n",
    "try:\n",
    "    cfg = Config.fromfile(METRIC3D_CONFIG_PATH)\n",
    "    cfg.model.backbone.use_mask_token = False\n",
    "    metric3d_model = MonoDepthModel(cfg).to(DEVICE)\n",
    "    checkpoint = torch.load(METRIC3D_MODEL_PATH, map_location=DEVICE)\n",
    "    state_dict = checkpoint.get('model_state_dict', checkpoint.get('model', checkpoint))\n",
    "    metric3d_model.load_state_dict(state_dict, strict=False)\n",
    "    metric3d_model.eval()\n",
    "    print(\">>> [SUCCESS] Metric3Dv2 模型加载成功！\")\n",
    "except Exception as e:\n",
    "    print(f\"!!! [FATAL ERROR] 加载 Metric3Dv2 模型时出错: {e}\")\n",
    "    raise\n",
    "\n",
    "# ==============================================================================\n",
    "# 4. 视频处理主函数\n",
    "# ==============================================================================\n",
    "def process_video_for_eval(input_path, output_txt_path):\n",
    "    print(f\"\\n--- 开始处理视频: {os.path.basename(input_path)} ---\")\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    metric3d_input_size = (cfg.data_basic['vit_size'][1], cfg.data_basic['vit_size'][0])\n",
    "    \n",
    "    tracker_args = SimpleNamespace(track_high_thresh=0.5, track_low_thresh=0.1, new_track_thresh=0.6, \n",
    "                                     track_buffer=30, match_thresh=0.8, mot20=False)\n",
    "    tracker = ByteTracker(args=tracker_args, frame_rate=fps)\n",
    "    STrack.release_id()\n",
    "    \n",
    "    # MODIFIED: Frame count now starts at 0 for KITTI format\n",
    "    frame_count = 0\n",
    "    with open(output_txt_path, 'w') as f_out:\n",
    "        with tqdm(total=total_frames, desc=f\"处理 {os.path.basename(input_path)}\") as pbar:\n",
    "            while cap.isOpened():\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "                \n",
    "                # a. 目标检测\n",
    "                det_results = yolo_model(frame, classes=[TARGET_CLASS_ID], verbose=False)[0]\n",
    "\n",
    "                # b. 深度估计\n",
    "                with torch.no_grad():\n",
    "                    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                    rgb_frame_resized = cv2.resize(rgb_frame, metric3d_input_size)\n",
    "                    rgb_torch = torch.from_numpy(rgb_frame_resized).permute(2, 0, 1).unsqueeze(0).float().to(DEVICE) / 255.0\n",
    "                    pred_output = metric3d_model(data={'input': rgb_torch})\n",
    "                    pred_depth_np = pred_output[0].squeeze().cpu().numpy()\n",
    "                    pred_depth_filtered = cv2.resize(pred_depth_np, (width, height))\n",
    "\n",
    "                # c. 准备带深度的检测结果\n",
    "                detections_with_depth = []\n",
    "                if det_results.boxes.shape[0] > 0:\n",
    "                    for box in det_results.boxes:\n",
    "                        x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                        score = box.conf[0].item()\n",
    "                        cls_id = box.cls[0].item()\n",
    "                        \n",
    "                        roi_w, roi_h = int((x2 - x1) * 0.25), int((y2 - y1) * 0.25)\n",
    "                        roi_x1, roi_y1 = x1 + ((x2-x1) - roi_w) // 2, y1 + ((y2-y1) - roi_h) // 2\n",
    "                        depth_roi = pred_depth_filtered[roi_y1:roi_y1+roi_h, roi_x1:roi_x1+roi_w]\n",
    "                        initial_depth = np.median(depth_roi) if depth_roi.size > 0 else 0.0\n",
    "                        detections_with_depth.append([x1, y1, x2, y2, score, cls_id, initial_depth])\n",
    "\n",
    "                # d. 更新跟踪器\n",
    "                # The output format is [x1, y1, x2, y2, track_id, score, class_id, depth]\n",
    "                tracks = tracker.update(np.array(detections_with_depth)) if len(detections_with_depth) > 0 else np.empty((0, 8))\n",
    "\n",
    "                # ========================================================================\n",
    "                # MODIFIED: Write results in the requested KITTI tracking format\n",
    "                # ========================================================================\n",
    "                if tracks.shape[0] > 0:\n",
    "                    for track in tracks:\n",
    "                        bb_left, bb_top, bb_right, bb_bottom = track[0], track[1], track[2], track[3]\n",
    "                        track_id = int(track[4])\n",
    "                        score = track[5]\n",
    "                        \n",
    "                        # Write the 17-column KITTI format string\n",
    "                        f_out.write(\n",
    "                            f\"{frame_count} {track_id} {TARGET_CLASS_NAME} -1 -1 -10 \"\n",
    "                            f\"{bb_left:.2f} {bb_top:.2f} {bb_right:.2f} {bb_bottom:.2f} \"\n",
    "                            f\"-1 -1 -1 -1000 -1000 -1000 -10 {score:.4f}\\n\"\n",
    "                        )\n",
    "                \n",
    "                # MODIFIED: Increment frame count at the end of the loop\n",
    "                frame_count += 1\n",
    "                pbar.update(1)\n",
    "\n",
    "    cap.release()\n",
    "    print(f\"--- 处理完成！输出已保存至: {output_txt_path} ---\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 5. 批量处理主程序\n",
    "# ==============================================================================\n",
    "if __name__ == '__main__':\n",
    "    print(\"\\n>>> [DEBUG] 步骤 5: 开始执行批量处理主程序...\")\n",
    "    \n",
    "    video_files = glob.glob(os.path.join(INPUT_VIDEOS_DIR, '*.mp4'))\n",
    "    if not video_files:\n",
    "        # Note: The error log showed kitti_videos, but doc specified input_videos. Double-check your path.\n",
    "        print(f\"!!! [WARNING] 在目录 {INPUT_VIDEOS_DIR} 中未找到任何 .mp4 视频文件。\")\n",
    "    else:\n",
    "        print(f\">>> [INFO] 找到 {len(video_files)} 个视频文件进行处理。\")\n",
    "\n",
    "    for video_path in sorted(video_files):\n",
    "        try:\n",
    "            video_name = os.path.basename(video_path)\n",
    "            output_name = os.path.splitext(video_name)[0] + '.txt'\n",
    "            output_path = os.path.join(OUTPUT_EVAL_DIR, output_name)\n",
    "            \n",
    "            process_video_for_eval(video_path, output_path)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"!!! [FATAL ERROR] 处理视频 {video_path} 时发生严重错误: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            continue\n",
    "\n",
    "    print(\"\\n>>> [DEBUG] 所有视频处理完毕。\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6aaa97-8cca-4fe3-acb4-5de30b160103",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mot_depth)",
   "language": "python",
   "name": "mot_depth"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
