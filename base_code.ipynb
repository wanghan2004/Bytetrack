{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4d3b7f1-4d13-4c88-aa7a-4ec5474c2323",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [DEBUG] 步骤 0: 检查关键库版本...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/mot_depth/lib/python3.9/site-packages/torch/utils/cpp_extension.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import packaging  # type: ignore[attr-defined]\n",
      "/root/miniconda3/envs/mot_depth/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/envs/mot_depth/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> [INFO] mmcv version: 1.7.2\n",
      ">>> [INFO] timm version: 0.6.12\n",
      ">>> [DEBUG] 步骤 0: 检查完成。\n",
      "============================================================\n",
      "\n",
      ">>> [DEBUG] 步骤 1: 开始导入核心库...\n",
      ">>> [DEBUG] 核心库 cv2, torch, numpy, ultralytics, tqdm, mmcv.Config 导入成功。\n",
      ">>> [DEBUG] 已将 '/root/autodl-tmp/Metric3D' 添加到系统路径。\n",
      ">>> [DEBUG] Metric3D 模块 'DepthModel' (作为 MonoDepthModel) 导入成功。\n",
      ">>> [DEBUG] 步骤 1: 所有库导入完成。\n",
      "============================================================\n",
      "\n",
      ">>> [DEBUG] 步骤 2: 配置模型和文件路径...\n",
      ">>> [DEBUG] 所有文件路径检查通过。\n",
      ">>> [DEBUG] 将要使用的设备: cuda\n",
      ">>> [DEBUG] 步骤 2: 配置完成。\n",
      "============================================================\n",
      "\n",
      ">>> [DEBUG] 步骤 3: 开始加载深度学习模型...\n",
      ">>> [DEBUG] 正在加载 YOLOv8 模型...\n",
      ">>> [DEBUG] YOLOv8 模型加载成功！\n",
      ">>> [INFO] YOLOv8 模型所有类别: {0: 'Car', 1: 'Pedestrian', 2: 'Cyclist'}\n",
      ">>> [INFO] 目标类别 'Car' 已找到, ID为: 0\n",
      ">>> [DEBUG] 正在加载 Metric3Dv2 模型...\n",
      ">>> [DEBUG] Part A: 配置加载成功。\n",
      ">>> [DEBUG] Part B: 模型初始化成功。\n",
      ">>> [DEBUG] Part C: 权重加载成功 (已忽略不匹配的键)。\n",
      ">>> [SUCCESS] Metric3Dv2 模型加载并移动到 GPU 成功！\n",
      ">>> [DEBUG] 步骤 3: 所有模型加载完成。\n",
      "============================================================\n",
      "\n",
      ">>> [DEBUG] 步骤 4: 定义视频处理函数...\n",
      ">>> [DEBUG] 步骤 4: 视频处理函数定义完成。\n",
      "============================================================\n",
      "\n",
      ">>> [DEBUG] 步骤 5: 开始执行主程序...\n",
      "\n",
      "--- 开始视频处理 ---\n",
      ">>> [INFO] Metric3D 模型输入尺寸 (宽, 高): (1064, 616)\n",
      ">>> [INFO] 输入视频信息: 1242x374 @ 1.00 FPS, 共 233 帧。\n",
      ">>> [INFO] 处理后的视频将保存至: /root/autodl-tmp/output_video_with_depth2.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "视频处理进度:   3%|▎         | 6/233 [00:02<01:43,  2.19it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 262\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m>>> [DEBUG] 步骤 5: 开始执行主程序...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 262\u001b[0m     \u001b[43mprocess_video_debug\u001b[49m\u001b[43m(\u001b[49m\u001b[43mINPUT_VIDEO_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mOUTPUT_VIDEO_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    264\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m!!! [FATAL ERROR] 在视频处理过程中发生严重错误: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[1], line 202\u001b[0m, in \u001b[0;36mprocess_video_debug\u001b[0;34m(input_path, output_path)\u001b[0m\n\u001b[1;32m    200\u001b[0m rgb_frame_resized \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(rgb_frame, metric3d_input_size)\n\u001b[1;32m    201\u001b[0m rgb_torch \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(rgb_frame_resized)\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mto(DEVICE) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255.0\u001b[39m\n\u001b[0;32m--> 202\u001b[0m pred_output \u001b[38;5;241m=\u001b[39m \u001b[43mmetric3d_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrgb_torch\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    203\u001b[0m pred_depth \u001b[38;5;241m=\u001b[39m pred_output[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    204\u001b[0m pred_depth_np \u001b[38;5;241m=\u001b[39m pred_depth\u001b[38;5;241m.\u001b[39msqueeze()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m~/miniconda3/envs/mot_depth/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/autodl-tmp/Metric3D/mono/model/model_pipelines/__base_model__.py:13\u001b[0m, in \u001b[0;36mBaseDepthModel.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, data):\n\u001b[0;32m---> 13\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdepth_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m'\u001b[39m], output[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfidence\u001b[39m\u001b[38;5;124m'\u001b[39m], output\n",
      "File \u001b[0;32m~/miniconda3/envs/mot_depth/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/autodl-tmp/Metric3D/mono/model/model_pipelines/dense_pipeline.py:15\u001b[0m, in \u001b[0;36mDensePredModel.forward\u001b[0;34m(self, input, **kwargs)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# [f_32, f_16, f_8, f_4]\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/miniconda3/envs/mot_depth/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/autodl-tmp/Metric3D/mono/model/decode_heads/RAFTDepthNormalDPTDecoder5.py:965\u001b[0m, in \u001b[0;36mRAFTDepthNormalDPT5.forward\u001b[0;34m(self, vit_features, **kwargs)\u001b[0m\n\u001b[1;32m    963\u001b[0m     net_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_block(net_list, inp_list, iter32\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, iter16\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, iter08\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, update\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    964\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_gru_layers \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mslow_fast_gru:\u001b[38;5;66;03m# Update low-res GRU and mid-res GRU\u001b[39;00m\n\u001b[0;32m--> 965\u001b[0m     net_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minp_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miter32\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_gru_layers\u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miter16\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miter08\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupdate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    966\u001b[0m net_list, up_mask, delta_flow \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_block(net_list, inp_list, \u001b[38;5;28;01mNone\u001b[39;00m, flow, iter32\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_gru_layers\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m3\u001b[39m, iter16\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_gru_layers\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    968\u001b[0m \u001b[38;5;66;03m# F(t+1) = F(t) + \\Delta(t)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mot_depth/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/autodl-tmp/Metric3D/mono/model/decode_heads/RAFTDepthNormalDPTDecoder5.py:387\u001b[0m, in \u001b[0;36mBasicMultiUpdateBlock.forward\u001b[0;34m(self, net, inp, corr, flow, iter08, iter16, iter32, update)\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, net, inp, corr\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, flow\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, iter08\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, iter16\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, iter32\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, update\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m iter32:\n\u001b[0;32m--> 387\u001b[0m         net[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgru32\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minp\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpool2x\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m iter16:\n\u001b[1;32m    389\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_gru_layers \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/mot_depth/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/autodl-tmp/Metric3D/mono/model/decode_heads/RAFTDepthNormalDPTDecoder5.py:349\u001b[0m, in \u001b[0;36mConvGRU.forward\u001b[0;34m(self, h, cz, cr, cq, *x_list)\u001b[0m\n\u001b[1;32m    343\u001b[0m q \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtanh((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvq(torch\u001b[38;5;241m.\u001b[39mcat([r\u001b[38;5;241m*\u001b[39mh, x], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)) \u001b[38;5;241m+\u001b[39m cq))\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# z = torch.sigmoid((self.convz(hx) + cz).float())\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# r = torch.sigmoid((self.convr(hx) + cr).float())\u001b[39;00m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;66;03m# q = torch.tanh((self.convq(torch.cat([r*h, x], dim=1)) + cq).float())\u001b[39;00m\n\u001b[0;32m--> 349\u001b[0m h \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m \u001b[38;5;241m+\u001b[39m z \u001b[38;5;241m*\u001b[39m q\n\u001b[1;32m    350\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m h\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# 0. 关键依赖库检查 (用于调试)\n",
    "# ==============================================================================\n",
    "print(\">>> [DEBUG] 步骤 0: 检查关键库版本...\")\n",
    "try:\n",
    "    import mmcv\n",
    "    import timm\n",
    "    print(f\">>> [INFO] mmcv version: {mmcv.__version__}\")\n",
    "    print(f\">>> [INFO] timm version: {timm.__version__}\")\n",
    "except ImportError as e:\n",
    "    print(f\"!!! [ERROR] 缺少核心调试库: {e}\")\n",
    "print(\">>> [DEBUG] 步骤 0: 检查完成。\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. 导入必要的库\n",
    "# ==============================================================================\n",
    "print(\">>> [DEBUG] 步骤 1: 开始导入核心库...\")\n",
    "try:\n",
    "    import cv2\n",
    "    import torch\n",
    "    import numpy as np\n",
    "    from ultralytics import YOLO\n",
    "    import sys\n",
    "    import os\n",
    "    from tqdm import tqdm\n",
    "    from mmcv import Config\n",
    "    print(\">>> [DEBUG] 核心库 cv2, torch, numpy, ultralytics, tqdm, mmcv.Config 导入成功。\")\n",
    "except ImportError as e:\n",
    "    print(f\"!!! [ERROR] 导入核心库失败: {e}\")\n",
    "    print(\"!!! [HINT] 请确保您已经按照教程正确安装了所有依赖。\")\n",
    "    raise\n",
    "\n",
    "# --- 导入 Metric3D 相关的模块 ---\n",
    "METRIC3D_PATH = '/root/autodl-tmp/Metric3D'\n",
    "if METRIC3D_PATH not in sys.path:\n",
    "    sys.path.insert(0, METRIC3D_PATH)\n",
    "    print(f\">>> [DEBUG] 已将 '{METRIC3D_PATH}' 添加到系统路径。\")\n",
    "\n",
    "try:\n",
    "    from mono.model.monodepth_model import DepthModel as MonoDepthModel\n",
    "    print(\">>> [DEBUG] Metric3D 模块 'DepthModel' (作为 MonoDepthModel) 导入成功。\")\n",
    "except ImportError as e:\n",
    "    print(f\"!!! [ERROR] 从 Metric3D 导入模块失败: {e}\")\n",
    "    print(f\"!!! [HINT] 请确认 Metric3D 的代码库是否存在于 '{METRIC3D_PATH}' 路径下。\")\n",
    "    raise\n",
    "\n",
    "print(\">>> [DEBUG] 步骤 1: 所有库导入完成。\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. 配置区域与路径检查\n",
    "# ==============================================================================\n",
    "print(\">>> [DEBUG] 步骤 2: 配置模型和文件路径...\")\n",
    "\n",
    "YOLO_MODEL_PATH = '/root/autodl-tmp/weights/epoch30.pt'\n",
    "METRIC3D_MODEL_PATH = '/root/autodl-tmp/weights/metric_depth_vit_large_800k.pth'\n",
    "METRIC3D_CONFIG_PATH = '/root/autodl-tmp/Metric3D/mono/configs/HourglassDecoder/vit.raft5.large.py'\n",
    "INPUT_VIDEO_PATH = '/root/autodl-tmp/kitti_videos/0002.mp4'\n",
    "OUTPUT_VIDEO_PATH = '/root/autodl-tmp/output_video_with_depth2.mp4'\n",
    "TRACKER_CONFIG_PATH = '/root/autodl-tmp/bytetrack.yaml'\n",
    "\n",
    "\n",
    "paths_to_check = {\n",
    "    \"YOLOv8 权重\": YOLO_MODEL_PATH,\n",
    "    \"Metric3D 权重\": METRIC3D_MODEL_PATH,\n",
    "    \"Metric3D 配置\": METRIC3D_CONFIG_PATH,\n",
    "    \"输入视频\": INPUT_VIDEO_PATH,\n",
    "    \"跟踪器配置\": TRACKER_CONFIG_PATH,\n",
    "}\n",
    "all_paths_ok = True\n",
    "for name, path in paths_to_check.items():\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"!!! [ERROR] 路径检查失败: {name} 文件未找到于 '{path}'\")\n",
    "        all_paths_ok = False\n",
    "\n",
    "if not all_paths_ok:\n",
    "    raise FileNotFoundError(\"一个或多个关键文件路径无效。请确保已创建 bytetrack.yaml 文件。\")\n",
    "else:\n",
    "    print(\">>> [DEBUG] 所有文件路径检查通过。\")\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\">>> [DEBUG] 将要使用的设备: {DEVICE}\")\n",
    "if DEVICE.type == 'cpu':\n",
    "    print(\"!!! [WARNING] 未检测到 CUDA 设备，将使用 CPU 运行。速度会很慢！\")\n",
    "\n",
    "print(\">>> [DEBUG] 步骤 2: 配置完成。\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. 模型加载\n",
    "# ==============================================================================\n",
    "print(\">>> [DEBUG] 步骤 3: 开始加载深度学习模型...\")\n",
    "# --- 加载 YOLOv8 & ByteTrack 模型 ---\n",
    "try:\n",
    "    print(\">>> [DEBUG] 正在加载 YOLOv8 模型...\")\n",
    "    yolo_model = YOLO(YOLO_MODEL_PATH)\n",
    "    print(\">>> [DEBUG] YOLOv8 模型加载成功！\")\n",
    "\n",
    "    # --- [新功能] 获取要跟踪的类别ID ---\n",
    "    TARGET_CLASS_NAME = 'Car'\n",
    "    TARGET_CLASS_ID = -1\n",
    "    # 打印模型所有类别，方便确认\n",
    "    print(f\">>> [INFO] YOLOv8 模型所有类别: {yolo_model.names}\")\n",
    "    # 自动查找'Car'类别的ID\n",
    "    for class_id, class_name in yolo_model.names.items():\n",
    "        if class_name == TARGET_CLASS_NAME:\n",
    "            TARGET_CLASS_ID = class_id\n",
    "            break\n",
    "    \n",
    "    if TARGET_CLASS_ID != -1:\n",
    "        print(f\">>> [INFO] 目标类别 '{TARGET_CLASS_NAME}' 已找到, ID为: {TARGET_CLASS_ID}\")\n",
    "    else:\n",
    "        raise ValueError(f\"错误：目标类别 '{TARGET_CLASS_NAME}' 在模型中未找到。\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"!!! [ERROR] 加载 YOLOv8 模型或查找类别ID时失败: {e}\")\n",
    "    raise\n",
    "\n",
    "# --- 加载 Metric3Dv2 模型 ---\n",
    "try:\n",
    "    print(\">>> [DEBUG] 正在加载 Metric3Dv2 模型...\")\n",
    "    \n",
    "    cfg = Config.fromfile(METRIC3D_CONFIG_PATH)\n",
    "    print(\">>> [DEBUG] Part A: 配置加载成功。\")\n",
    "\n",
    "    cfg.model.backbone.use_mask_token = False\n",
    "        \n",
    "    metric3d_model = MonoDepthModel(cfg).to(DEVICE)\n",
    "    print(\">>> [DEBUG] Part B: 模型初始化成功。\")\n",
    "\n",
    "    checkpoint = torch.load(METRIC3D_MODEL_PATH, map_location=DEVICE)\n",
    "    \n",
    "    if 'model_state_dict' in checkpoint:\n",
    "        state_dict = checkpoint['model_state_dict']\n",
    "    elif 'model' in checkpoint:\n",
    "        state_dict = checkpoint['model']\n",
    "    else:\n",
    "        state_dict = checkpoint\n",
    "\n",
    "    metric3d_model.load_state_dict(state_dict, strict=False)\n",
    "    print(\">>> [DEBUG] Part C: 权重加载成功 (已忽略不匹配的键)。\")\n",
    "    \n",
    "    metric3d_model.eval()\n",
    "    print(\">>> [SUCCESS] Metric3Dv2 模型加载并移动到 GPU 成功！\")\n",
    "except Exception as e:\n",
    "    print(f\"!!! [FATAL ERROR] 加载 Metric3Dv2 模型时出错: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    raise\n",
    "\n",
    "print(\">>> [DEBUG] 步骤 3: 所有模型加载完成。\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 4. 视频处理主函数\n",
    "# ==============================================================================\n",
    "print(\">>> [DEBUG] 步骤 4: 定义视频处理函数...\")\n",
    "def process_video_debug(input_path, output_path):\n",
    "    print(\"\\n--- 开始视频处理 ---\")\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"!!! [ERROR] 无法打开视频文件: {input_path}\")\n",
    "        return\n",
    "\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    metric3d_input_size = (cfg.data_basic['vit_size'][1], cfg.data_basic['vit_size'][0])\n",
    "    print(f\">>> [INFO] Metric3D 模型输入尺寸 (宽, 高): {metric3d_input_size}\")\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "    \n",
    "    print(f\">>> [INFO] 输入视频信息: {width}x{height} @ {fps:.2f} FPS, 共 {total_frames} 帧。\")\n",
    "    print(f\">>> [INFO] 处理后的视频将保存至: {output_path}\")\n",
    "\n",
    "    with tqdm(total=total_frames, desc=\"视频处理进度\") as pbar:\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            # --- [核心修改 1] ---\n",
    "            # 使用 classes 参数指定只跟踪 'Car' 类别\n",
    "            track_results = yolo_model.track(\n",
    "                frame, \n",
    "                persist=True, \n",
    "                verbose=False, \n",
    "                tracker=TRACKER_CONFIG_PATH,\n",
    "                classes=[TARGET_CLASS_ID] \n",
    "            )\n",
    "            \n",
    "            # --- [核心修改 2] ---\n",
    "            # 不再使用 track_results[0].plot()，改为手动绘制\n",
    "            # 首先创建一个当前帧的副本用于绘制\n",
    "            annotated_frame = frame.copy()\n",
    "\n",
    "            # 深度估计部分 (逻辑不变)\n",
    "            with torch.no_grad():\n",
    "                rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                rgb_frame_resized = cv2.resize(rgb_frame, metric3d_input_size)\n",
    "                rgb_torch = torch.from_numpy(rgb_frame_resized).permute(2, 0, 1).unsqueeze(0).float().to(DEVICE) / 255.0\n",
    "                pred_output = metric3d_model(data={'input': rgb_torch})\n",
    "                pred_depth = pred_output[0]\n",
    "                pred_depth_np = pred_depth.squeeze().cpu().numpy()\n",
    "                pred_depth_resized = cv2.resize(pred_depth_np, (width, height))\n",
    "\n",
    "            # 获取跟踪结果\n",
    "            boxes = track_results[0].boxes.xyxy.cpu().numpy()\n",
    "            track_ids = []\n",
    "            if track_results[0].boxes.id is not None:\n",
    "                track_ids = track_results[0].boxes.id.int().cpu().tolist()\n",
    "\n",
    "            # 循环遍历每个被跟踪到的目标，手动绘制\n",
    "            if len(track_ids) > 0:\n",
    "                for box, track_id in zip(boxes, track_ids):\n",
    "                    x1, y1, x2, y2 = map(int, box)\n",
    "                    \n",
    "                    # 1. 绘制检测框 (绿色，粗细为2)\n",
    "                    cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                    \n",
    "                    # 2. 计算并绘制ID和深度信息 (逻辑不变)\n",
    "                    box_w, box_h = x2 - x1, y2 - y1\n",
    "                    roi_w, roi_h = int(box_w * 0.5), int(box_h * 0.5)\n",
    "                    roi_x1 = max(x1 + (box_w - roi_w) // 2, 0)\n",
    "                    roi_y1 = max(y1 + (box_h - roi_h) // 2, 0)\n",
    "                    roi_x2 = min(roi_x1 + roi_w, width)\n",
    "                    roi_y2 = min(roi_y1 + roi_h, height)\n",
    "\n",
    "                    depth_roi = pred_depth_resized[roi_y1:roi_y2, roi_x1:roi_x2]\n",
    "                    \n",
    "                    if depth_roi.size > 0:\n",
    "                        sorted_depths = np.sort(depth_roi.flatten())\n",
    "                        cut_off = int(len(sorted_depths) * 0.05)\n",
    "                        \n",
    "                        if len(sorted_depths) > 2 * cut_off:\n",
    "                            filtered_depths = sorted_depths[cut_off:-cut_off]\n",
    "                            avg_depth = np.mean(filtered_depths) if filtered_depths.size > 0 else 0\n",
    "                        else:\n",
    "                            avg_depth = np.mean(sorted_depths) if sorted_depths.size > 0 else 0\n",
    "                        \n",
    "                        depth_text = f\"ID:{track_id} D:{avg_depth:.2f}m\"\n",
    "                        (text_w, text_h), _ = cv2.getTextSize(depth_text, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)\n",
    "                        cv2.rectangle(annotated_frame, (x1, y1 - 25), (x1 + text_w + 5, y1 - 5), (0, 100, 0), -1)\n",
    "                        cv2.putText(annotated_frame, depth_text, (x1 + 2, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "\n",
    "            out.write(annotated_frame)\n",
    "            pbar.update(1)\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(f\"\\n--- 视频处理完成！ ---\")\n",
    "    print(f\">>> [SUCCESS] 输出视频已成功保存到: {output_path}\")\n",
    "\n",
    "print(\">>> [DEBUG] 步骤 4: 视频处理函数定义完成。\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 5. 运行主程序\n",
    "# ==============================================================================\n",
    "print(\">>> [DEBUG] 步骤 5: 开始执行主程序...\")\n",
    "try:\n",
    "    process_video_debug(INPUT_VIDEO_PATH, OUTPUT_VIDEO_PATH)\n",
    "except Exception as e:\n",
    "    print(f\"!!! [FATAL ERROR] 在视频处理过程中发生严重错误: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    print(\"!!! [HINT] 请检查上面的错误信息。可能的原因包括：CUDA内存不足、模型与输入数据维度不匹配等。\")\n",
    "\n",
    "print(\">>> [DEBUG] 步骤 5: 主程序执行完毕。\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "305c4562-90c5-4017-abc6-7c25bcafbe97",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: ultralytics in /root/miniconda3/envs/mot_depth/lib/python3.9/site-packages (8.3.213)\n",
      "Requirement already satisfied: numpy>=1.23.0 in /root/miniconda3/envs/mot_depth/lib/python3.9/site-packages (from ultralytics) (1.23.1)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /root/miniconda3/envs/mot_depth/lib/python3.9/site-packages (from ultralytics) (3.9.4)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /root/miniconda3/envs/mot_depth/lib/python3.9/site-packages (from ultralytics) (4.11.0.86)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /root/miniconda3/envs/mot_depth/lib/python3.9/site-packages (from ultralytics) (11.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /root/miniconda3/envs/mot_depth/lib/python3.9/site-packages (from ultralytics) (6.0.3)\n",
      "Requirement already satisfied: requests>=2.23.0 in /root/miniconda3/envs/mot_depth/lib/python3.9/site-packages (from ultralytics) (2.32.5)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /root/miniconda3/envs/mot_depth/lib/python3.9/site-packages (from ultralytics) (1.13.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in /root/miniconda3/envs/mot_depth/lib/python3.9/site-packages (from ultralytics) (2.0.1)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /root/miniconda3/envs/mot_depth/lib/python3.9/site-packages (from ultralytics) (0.15.2)\n",
      "Requirement already satisfied: psutil in /root/miniconda3/envs/mot_depth/lib/python3.9/site-packages (from ultralytics) (7.1.0)\n",
      "Requirement already satisfied: polars in /root/miniconda3/envs/mot_depth/lib/python3.9/site-packages (from ultralytics) (1.34.0)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in /root/miniconda3/envs/mot_depth/lib/python3.9/site-packages (from ultralytics) (2.0.17)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /root/miniconda3/envs/mot_depth/lib/python3.9/site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /root/miniconda3/envs/mot_depth/lib/python3.9/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /root/miniconda3/envs/mot_depth/lib/python3.9/site-packages (from matplotlib>=3.3.0->ultralytics) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /root/miniconda3/envs/mot_depth/lib/python3.9/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /root/miniconda3/envs/mot_depth/lib/python3.9/site-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /root/miniconda3/envs/mot_depth/lib/python3.9/site-packages (from matplotlib>=3.3.0->ultralytics) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /root/miniconda3/envs/mot_depth/lib/python3.9/site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /root/miniconda3/envs/mot_depth/lib/python3.9/site-packages (from matplotlib>=3.3.0->ultralytics) (6.5.2)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /root/miniconda3/envs/mot_depth/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib>=3.3.0->ultralytics) (3.23.0)\n",
      "Requirement already satisfied: six>=1.5 in /root/miniconda3/envs/mot_depth/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /root/miniconda3/envs/mot_depth/lib/python3.9/site-packages (from requests>=2.23.0->ultralytics) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/miniconda3/envs/mot_depth/lib/python3.9/site-packages (from requests>=2.23.0->ultralytics) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/miniconda3/envs/mot_depth/lib/python3.9/site-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/miniconda3/envs/mot_depth/lib/python3.9/site-packages (from requests>=2.23.0->ultralytics) (2025.10.5)\n",
      "Requirement already satisfied: filelock in /root/miniconda3/envs/mot_depth/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions in /root/miniconda3/envs/mot_depth/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
      "Requirement already satisfied: sympy in /root/miniconda3/envs/mot_depth/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (1.14.0)\n",
      "Requirement already satisfied: networkx in /root/miniconda3/envs/mot_depth/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /root/miniconda3/envs/mot_depth/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /root/miniconda3/envs/mot_depth/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /root/miniconda3/envs/mot_depth/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /root/miniconda3/envs/mot_depth/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /root/miniconda3/envs/mot_depth/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /root/miniconda3/envs/mot_depth/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /root/miniconda3/envs/mot_depth/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /root/miniconda3/envs/mot_depth/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /root/miniconda3/envs/mot_depth/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /root/miniconda3/envs/mot_depth/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /root/miniconda3/envs/mot_depth/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /root/miniconda3/envs/mot_depth/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /root/miniconda3/envs/mot_depth/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (2.0.0)\n",
      "Requirement already satisfied: setuptools in /root/miniconda3/envs/mot_depth/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.8.0->ultralytics) (80.9.0)\n",
      "Requirement already satisfied: wheel in /root/miniconda3/envs/mot_depth/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.8.0->ultralytics) (0.45.1)\n",
      "Requirement already satisfied: cmake in /root/miniconda3/envs/mot_depth/lib/python3.9/site-packages (from triton==2.0.0->torch>=1.8.0->ultralytics) (4.1.0)\n",
      "Requirement already satisfied: lit in /root/miniconda3/envs/mot_depth/lib/python3.9/site-packages (from triton==2.0.0->torch>=1.8.0->ultralytics) (18.1.8)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /root/miniconda3/envs/mot_depth/lib/python3.9/site-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\n",
      "Requirement already satisfied: polars-runtime-32==1.34.0 in /root/miniconda3/envs/mot_depth/lib/python3.9/site-packages (from polars->ultralytics) (1.34.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /root/miniconda3/envs/mot_depth/lib/python3.9/site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1759e75-7c5b-484d-a59c-6bd6b8a37013",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting lap\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/2f/ab/070be2dc9e56b368031168710c848be203523c7c83d9d22ce7fde6a167fe/lap-0.5.12-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.21.6 in /root/miniconda3/envs/mot_depth/lib/python3.9/site-packages (from lap) (1.23.1)\n",
      "Installing collected packages: lap\n",
      "Successfully installed lap-0.5.12\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install lap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9215cf4-57ff-47fa-bb85-7a6556ddc037",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mot_depth)",
   "language": "python",
   "name": "mot_depth"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
